{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAC Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Author():\n",
    "    def __init__(self, name, aid):\n",
    "        self.name = name\n",
    "        self.aid = aid\n",
    "        self.nicknames = []\n",
    "        self.paper_ids = []\n",
    "    \n",
    "    def add_paper(self, pid):\n",
    "        if pid not in self.paper_ids:\n",
    "            self.paper_ids.append(pid)\n",
    "            \n",
    "    def add_nickname(self, name):\n",
    "        if name not in self.nicknames:\n",
    "            self.nicknames.append(name)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Paper():\n",
    "    def __init__(self, title, abstract, year, author_names, b_topic, topics, pid, detc, url):\n",
    "        \n",
    "        # Basic info\n",
    "        self.title = title\n",
    "        self.abstract = abstract\n",
    "        self.year = year\n",
    "        self.author_names = author_names\n",
    "        self.broad_topic = b_topic\n",
    "        self.topics = topics\n",
    "        self.pid = pid\n",
    "        self.detc = detc\n",
    "        self.url = url\n",
    "        \n",
    "        # add later\n",
    "        self.author_ids = []\n",
    "        self.citations = []\n",
    "        self.cited_by = []\n",
    "    \n",
    "    def add_author_id(self, aid):\n",
    "        if aid not in self.author_ids:\n",
    "            self.author_ids.append(aid)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Procedure 1. Read papers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = \"data/DAC_Entire_DataBase.json\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    database = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "papers = {}\n",
    "for p in database:\n",
    "    paper = Paper(p['Title'], p['Abstract'],p['Year'],p['Authors'], p['Broad_Topic'],\\\n",
    "                  p['Topics'], p['PaperID'],p['DETC'], p['URL'])\n",
    "    papers[paper.pid] = paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure 2. Read authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## add author into the dataset\n",
    "author_names = {}\n",
    "\n",
    "for p in papers.values():\n",
    "    for n in p.author_names:\n",
    "        author_names[n] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign IDs to each author\n",
    "\n",
    "id = 0\n",
    "for n in author_names.keys():\n",
    "    author_names[n] = str(id)\n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authors = {}\n",
    "\n",
    "for name in author_names.keys():\n",
    "    authors[author_names[name]] = Author(name, author_names[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_name_to_author_dict(authors):\n",
    "    ret = {}\n",
    "    for author in authors.values():\n",
    "        ret[author.name] = author\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Connection (between author and paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name2author = make_name_to_author_dict(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2515"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name2author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let each author has paper_id list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for paper in papers.values():\n",
    "    for name in paper.author_names:\n",
    "        author = name2author[name]\n",
    "        \n",
    "        author.add_paper(paper.pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let each paper has author_id list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for paper in papers.values():\n",
    "    for name in paper.author_names:\n",
    "        paper.add_author_id(name2author[name].aid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Name Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect similar name pairs\n",
    "\n",
    "Running the following cell will generate lines of similar names. Each line is formatted as \"author_id, name, author_id, name\". For each line, it the two are indeed similar, them copy and paste the line into data/disambiguation.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import Levenshtein\n",
    "keys = name2author.keys()\n",
    "\n",
    "for i in range(0, len(keys)):\n",
    "    for j in range(i+1, len(keys)):\n",
    "        p1 = name2author[keys[i]]\n",
    "        p2 = name2author[keys[j]]\n",
    "        \n",
    "        first = p1.name\n",
    "        second = p2.name\n",
    "        \n",
    "        pdist = fuzz.partial_ratio(first, second)\n",
    "        dist = Levenshtein.distance(first, second)\n",
    "        lv_ra = Levenshtein.ratio(first, second)\n",
    "        \n",
    "        if pdist >90 or dist <=2 or lv_ra >0.8:\n",
    "            print p1.aid+\"\\t\"+first+\"\\t\"+p2.aid+\"\\t\"+second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for merging name1 and name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge(id1, id2, authors, papers):\n",
    "    author1 = authors[id1]\n",
    "    author2 = authors[id2]\n",
    "    \n",
    "    # 1. On Author level\n",
    "    \n",
    "    # let 1 has 2's all paper_ids\n",
    "    for pid in author2.paper_ids:\n",
    "        author1.add_paper(pid)\n",
    "    \n",
    "    # make 2's name as 1's nickname\n",
    "    author1.add_nickname(author2.name)\n",
    "    \n",
    "    # 2. On Papers level\n",
    "    # Make author2's papers that contain author2.id now contain author1.id\n",
    "    for pid in author2.paper_ids:\n",
    "        paper = papers[pid]\n",
    "        paper.author_ids = [id1 if x == id2 else x for x in paper.author_ids]\n",
    "    \n",
    "    # remove id2\n",
    "    authors.pop(id2)\n",
    "    \n",
    "    print author1.name, \" AND \", author2.name, \"ARE MERGED!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from disambiguation file\n",
    "\n",
    "Think of these name pairs as edges in graph, we need to find connected components of that graph and each component is referring to a person's name set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.Graph()\n",
    "disamb_file_path = \"data/disambiguation.txt\"\n",
    "\n",
    "dependency = []\n",
    "with open(disamb_file_path, \"rb\") as f:\n",
    "    for line in f:\n",
    "        segs = line.strip().split(\"\\t\")\n",
    "        id1 = segs[0]\n",
    "        id2 = segs[2]\n",
    "        G.add_edge(int(id1), int(id2))\n",
    "\n",
    "names = [sorted(list(c)) for c in sorted(nx.connected_components(G), key=len, reverse=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Richard J. Malak, Jr.  AND  Richard J. Malak ARE MERGED!\n",
      "Richard Malak  AND  Richard J. Malak, Jr. ARE MERGED!\n",
      "Kenneth Chase  AND  Ken W. Chase ARE MERGED!\n",
      "Kenneth W. Chase  AND  Kenneth Chase ARE MERGED!\n",
      "Ali Farhang-Mehr  AND  Ali Farhang Mehr ARE MERGED!\n",
      "A. Farhang-Mehr  AND  Ali Farhang-Mehr ARE MERGED!\n",
      "Jami J. Shah  AND  Jami Shah ARE MERGED!\n",
      "J. J. Shah  AND  Jami J. Shah ARE MERGED!\n",
      "Fuewen Frank Liou  AND  Frank Liou ARE MERGED!\n",
      "Frank W. Liou  AND  Fuewen Frank Liou ARE MERGED!\n",
      "George Fadel  AND  Georges M. Fadel ARE MERGED!\n",
      "Georges Fadel  AND  George Fadel ARE MERGED!\n",
      "Bryony L. DuPont  AND  Bryony DuPont ARE MERGED!\n",
      "Bryony L. Du Pont  AND  Bryony L. DuPont ARE MERGED!\n",
      "Carolyn Seepersad  AND  Carolyn C. Seepersad ARE MERGED!\n",
      "Carolyn Conner Seepersad  AND  Carolyn Seepersad ARE MERGED!\n",
      "Panos Papalambros  AND  P. Papalambros ARE MERGED!\n",
      "Panos Y. Papalambros  AND  Panos Papalambros ARE MERGED!\n",
      "Nam H. Kim  AND  Nam Ho Kim ARE MERGED!\n",
      "Nam-Ho Kim  AND  Nam H. Kim ARE MERGED!\n",
      "Katie Whitefoot  AND  Kate Whitefoot ARE MERGED!\n",
      "Kate S. Whitefoot  AND  Katie Whitefoot ARE MERGED!\n",
      "David Johnson  AND  David E. Johnson ARE MERGED!\n",
      "James Allison  AND  James T. Allison ARE MERGED!\n",
      "David J. Gorsich  AND  David Gorsich ARE MERGED!\n",
      "J. K. Davidson  AND  Joseph K. Davidson ARE MERGED!\n",
      "T. R. Langerak  AND  Thomas R. Langerak ARE MERGED!\n",
      "Steve C. Wang  AND  C. Wang ARE MERGED!\n",
      "Niclas Stromberg  AND  Niclas Strömberg ARE MERGED!\n",
      "Irem Tumer  AND  Irem Y. Tumer ARE MERGED!\n",
      "Art Boyars  AND  A. Boyars ARE MERGED!\n",
      "Jianxin (Roger) Jiao  AND  Jianxin Roger Jiao ARE MERGED!\n",
      "Ching-Shin Norman Shiau  AND  Ching-Shin Shiau ARE MERGED!\n",
      "Matthew I. Campbell  AND  Matthew Campbell ARE MERGED!\n",
      "Jitesh Panchal  AND  Jitesh H. Panchal ARE MERGED!\n",
      "J. Hamel  AND  J. M. Hamel ARE MERGED!\n",
      "J.-C. Léon  AND  J. C. Léon ARE MERGED!\n",
      "Yu Song  AND  Y. Song ARE MERGED!\n",
      "Raj Mishra  AND  Rajul Misra ARE MERGED!\n",
      "Thomas Stone  AND  Thomas M. Stone ARE MERGED!\n",
      "Ashraf Nassef  AND  Ashraf O. Nassef ARE MERGED!\n",
      "J. S. M. Vergeest  AND  Joris S. M. Vergeest ARE MERGED!\n",
      "Bart D. Frischknecht  AND  Bart Frischknecht ARE MERGED!\n",
      "I. Horváth  AND  Imre Horváth ARE MERGED!\n",
      "Sayed M. Metwalli  AND  Sayed Metwalli ARE MERGED!\n",
      "John Ziegert  AND  John C. Ziegert ARE MERGED!\n",
      "Judy Vance  AND  Judy M. Vance ARE MERGED!\n",
      "David C. Anderson  AND  David Anderson ARE MERGED!\n",
      "Andrew T. Olewnik  AND  Andrew Olewnik ARE MERGED!\n",
      "David Shahan  AND  David W. Shahan ARE MERGED!\n",
      "Mark A. Ganter  AND  Mark Ganter ARE MERGED!\n",
      "Horea Ilies  AND  Horea T. Ilies ARE MERGED!\n",
      "G. Gary Wang  AND  Gary Wang ARE MERGED!\n",
      "Shintaro Yamasaki  AND  Shintarou Yamasaki ARE MERGED!\n",
      "Mohamed Trabia  AND  Mohamed B. Trabia ARE MERGED!\n",
      "V. Krishnamurthy  AND  Vivek Krishnamurthy ARE MERGED!\n",
      "Mohamed Aly  AND  Mohamed F. Aly ARE MERGED!\n",
      "Jason M. Weaver  AND  Jason Weaver ARE MERGED!\n",
      "James L. Mathieson  AND  James J. Mason ARE MERGED!\n",
      "Peter A. Fenyes  AND  Peter Fenyes ARE MERGED!\n",
      "Brendan J. O’Toole  AND  Brendan O’Toole ARE MERGED!\n",
      "Kurt A. Chipperfield  AND  Kurt Chipperfield ARE MERGED!\n",
      "Matthew McIntire  AND  Matthew G. McIntire ARE MERGED!\n",
      "Alice Agogino  AND  Alice M. Agogino ARE MERGED!\n",
      "Ritesh A. Khire  AND  Ritesh Khire ARE MERGED!\n",
      "Sinobu Yoshimura  AND  Shinobu Yoshimura ARE MERGED!\n",
      "James Oliver  AND  James H. Oliver ARE MERGED!\n",
      "S. Manoochehri  AND  Souran Manoochehri ARE MERGED!\n",
      "Dennis N. Assanis  AND  Dennis Assanis ARE MERGED!\n",
      "Mohamed M. Shalaby  AND  Mohammed Shalaby ARE MERGED!\n",
      "J. P. Pernot  AND  J.-P. Pernot ARE MERGED!\n",
      "R. J. Yang  AND  R.-J. Yang ARE MERGED!\n",
      "Ayman Youssef  AND  Ayman M. A. Youssef ARE MERGED!\n",
      "Olivier de Weck  AND  Olivier L. de Weck ARE MERGED!\n",
      "Eliot H. Winer  AND  Eliot Winer ARE MERGED!\n",
      "Gary Stump  AND  Gary M. Stump ARE MERGED!\n",
      "Kenneth M. Bryden  AND  Kenneth (Mark) Bryden ARE MERGED!\n",
      "Nagesh Kulkarni  AND  Nagesh H. Kulkarni ARE MERGED!\n",
      "Paul D. Arendt  AND  Paul Arendt ARE MERGED!\n",
      "Janis Terpenny  AND  Janis P. Terpenny ARE MERGED!\n",
      "Kemper E. Lewis  AND  Kemper Lewis ARE MERGED!\n",
      "Alan R. Parkinson  AND  Alan Parkinson ARE MERGED!\n",
      "Richard H. Crawford  AND  Richard Crawford ARE MERGED!\n",
      "M. Steven Greene  AND  Steven Greene ARE MERGED!\n",
      "Samuel Drake  AND  Sam Drake ARE MERGED!\n",
      "Gül E. Okudan Kremer  AND  Gül E. Okudan ARE MERGED!\n",
      "C. G. Jensen  AND  C. Greg Jensen ARE MERGED!\n",
      "Joseph A. Donndelinger  AND  Joseph Donndelinger ARE MERGED!\n",
      "Sundar Krishnamurthy  AND  Sundar Krishnamurty ARE MERGED!\n",
      "Roger Jianxin Jiao  AND  Jianxin Jiao ARE MERGED!\n",
      "Zhi-Gang Xu  AND  Zhi Gang Xu ARE MERGED!\n",
      "Maria Yang  AND  Maria C. Yang ARE MERGED!\n",
      "Ian Tseng  AND  Ian H. Tseng ARE MERGED!\n",
      "Joshua D. Summers  AND  Joshua Summers ARE MERGED!\n",
      "Jered Dean  AND  Jered H. Dean ARE MERGED!\n",
      "Mark F. Horstemeyer  AND  M. F. Horstemeyer ARE MERGED!\n",
      "Kristin L. Wood  AND  Kristin Wood ARE MERGED!\n",
      "Mohamed El-Morsi  AND  Mohamed El Morsi ARE MERGED!\n",
      "Erin F. MacDonald  AND  Erin MacDonald ARE MERGED!\n",
      "Steve B. Shooter  AND  Steven B. Shooter ARE MERGED!\n",
      "Annette Skowronska  AND  Annette G. Skowronska ARE MERGED!\n",
      "Sara E. Lego  AND  Sara Lego ARE MERGED!\n",
      "Kambiz H. Hajikolaei  AND  Kambiz Haji Hajikolaei ARE MERGED!\n",
      "Linda Lianfeng Zhang  AND  Lianfeng Zhang ARE MERGED!\n",
      "Tobias Larsson  AND  Tobias C. Larsson ARE MERGED!\n",
      "Alejandro Diaz  AND  Alejandro R. Diaz ARE MERGED!\n",
      "Yoo Suk Hong  AND  Yoo S. Hong ARE MERGED!\n",
      "Scott Ferguson  AND  Scott M. Ferguson ARE MERGED!\n",
      "David W. Rosen  AND  David Rosen ARE MERGED!\n",
      "David A. Romero  AND  David Romero ARE MERGED!\n",
      "Christopher Garneau  AND  Christopher J. Garneau ARE MERGED!\n",
      "Mustafa H. Arafa  AND  Mustafa Arafa ARE MERGED!\n",
      "Adel Younis  AND  Adel A. Younis ARE MERGED!\n",
      "Matthew P. Reed  AND  Matthew Reed ARE MERGED!\n",
      "Matthew P. Castanier  AND  Matthew Castanier ARE MERGED!\n",
      "Hesham A. Hegazi  AND  Hesham Hegazi ARE MERGED!\n",
      "Sang Hoon Lee  AND  Sanghoon Lee ARE MERGED!\n",
      "W. F. Lu  AND  Wen F. Lu ARE MERGED!\n",
      "Matthew B. Parkinson  AND  Matthew Parkinson ARE MERGED!\n",
      "Kezheng Huang  AND  Ke-Zheng Huang ARE MERGED!\n",
      "Tucker J. Marion  AND  Tucker Marion ARE MERGED!\n",
      "Brandon M. Haley  AND  Brandon Haley ARE MERGED!\n",
      "Magnus Thor Jonsson  AND  Magnus Th. Jonsson ARE MERGED!\n",
      "Ashwin Gurnani  AND  Ashwin P. Gurnani ARE MERGED!\n",
      "Sang Won Lee  AND  Sangwon Lee ARE MERGED!\n",
      "Ye Li  AND  Y. Li ARE MERGED!\n",
      "Ehsan T. Esfahani  AND  Ehsan Tarkesh Esfahani ARE MERGED!\n",
      "Cristina H. Amon  AND  Cristina Amon ARE MERGED!\n",
      "Nicholas J. Gaul  AND  Nicholas Gaul ARE MERGED!\n",
      "R. D. Sriram  AND  Ram D. Sriram ARE MERGED!\n",
      "Sanjay Joshi  AND  Sanjay B. Joshi ARE MERGED!\n",
      "Harrison M. Kim  AND  Harrison Kim ARE MERGED!\n",
      "Jeremy J. Michalek  AND  Jeremy Michalek ARE MERGED!\n",
      "Stella Maris Oggianu  AND  Stella Oggianu ARE MERGED!\n",
      "Vincent Blouin  AND  Vincent Y. Blouin ARE MERGED!\n",
      "Warren P. Seering  AND  Warren Seering ARE MERGED!\n",
      "Dmitriy A. Dikin  AND  Dmitriy Dikin ARE MERGED!\n",
      "George Cheng  AND  George H. Cheng ARE MERGED!\n",
      "O. Ma  AND  Ou Ma ARE MERGED!\n",
      "Tomohiro Taguchi  AND  Tomohiro Mizoguchi ARE MERGED!\n",
      "Bianca Facidieno  AND  Bianca Falcidieno ARE MERGED!\n"
     ]
    }
   ],
   "source": [
    "for name_list in names:\n",
    "    for i in range(0, len(name_list)-1):\n",
    "        idx = len(name_list) - 1 - i\n",
    "        merge(str(name_list[idx-1]), str(name_list[idx]), authors, papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pairs(input_list):\n",
    "    length = len(input_list)\n",
    "    ret = []\n",
    "    if length == 1:\n",
    "        return [(input_list[0], input_list[0])]\n",
    "    for i in range(0, length-1):\n",
    "        for j in range(i+1, length):\n",
    "            ret.append((input_list[i], input_list[j]))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def papers_by_year(papers, inf, sup):\n",
    "    ret = []\n",
    "    for p in papers.values():\n",
    "        if p.year <= sup and p.year >= inf:\n",
    "            ret.append(p)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_edges(papers_selected):\n",
    "    edge_list = []\n",
    "    for p in papers_selected:\n",
    "        edge_list.extend(make_pairs(p.author_ids))\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def author_network(papers, inf_year, sup_year):\n",
    "    papers_between = papers_by_year(papers, inf_year, sup_year)\n",
    "    edge_list = make_edges(papers_between)\n",
    "    \n",
    "    G=nx.Graph()\n",
    "    for edge in edge_list:\n",
    "        G.add_edge(edge[0], edge[1])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_author_node(author_list):\n",
    "    node_list = [\"id\\tname\"]\n",
    "    for author in author_list:\n",
    "        node_info = \"\\t\".join([author.aid, author.name])\n",
    "        node_list.append(node_info)\n",
    "    return node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_paper_node(paper_list):\n",
    "    node_list = [\"id\\ttitle\"]\n",
    "    for paper in paper_list:\n",
    "        node_info = \"\\t\".join([paper.pid, paper.title])\n",
    "        node_list.append(node_info)\n",
    "    return node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_to_file(info_list, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        for line in info_list:\n",
    "            f.write(line)\n",
    "            f.write(\"\\n\")\n",
    "    print filename, \"DONE!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Interpreter():\n",
    "    def __init__(self):\n",
    "        self.digit_holder = {}\n",
    "        self.string_holder = {}\n",
    "        \n",
    "    def add(self, key, value):\n",
    "        self.digit_holder[key] = value\n",
    "        self.string_holder[value] = key\n",
    "    \n",
    "    def lookup(self, key):\n",
    "        if type(key) is int:\n",
    "            return self.digit_holder[key]\n",
    "        else:\n",
    "            return self.string_holder[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_aid = Interpreter()\n",
    "fake_pid = Interpreter()\n",
    "\n",
    "for i in range(0, len(authors.keys())):\n",
    "    aid = authors.keys()[i]\n",
    "    fake_aid.add(i, aid)\n",
    "    \n",
    "for i in range(0, len(papers.keys())):\n",
    "    pid = papers.keys()[i]\n",
    "    fake_pid.add(i, pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pairs(input_list):\n",
    "    length = len(input_list)\n",
    "    ret = []\n",
    "    if length <= 1:\n",
    "        return []\n",
    "    for i in range(0, length-1):\n",
    "        for j in range(i+1, length):\n",
    "            ret.append((input_list[i], input_list[j]))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Author Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def author_network(authors, papers, start_year, end_year):\n",
    "    edge_list = []\n",
    "    #edge_list = [\"from\\tto\\tweight\\tpaper\"]\n",
    "    for p in papers.values():\n",
    "        if p.year < start_year or p.year > end_year:\n",
    "            continue\n",
    "        author_ids = p.author_ids\n",
    "        edges = make_pairs(author_ids)\n",
    "        for edge in edges:\n",
    "            # print edge\n",
    "            edge_list.append(\"\\t\".join([edge[0], edge[1], \"10\", p.title]))\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def author_from_edgelist(edge_list):\n",
    "    author_set = set()\n",
    "    for edge in edge_list:\n",
    "        segs = edge.split(\"\\t\")\n",
    "        author_set.add(segs[0])\n",
    "        author_set.add(segs[1])\n",
    "    return list(author_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network_output(authors, papers, start_year, end_year, edge_file, node_file):\n",
    "    edge_list = author_network(authors, papers, start_year, end_year)\n",
    "    \n",
    "    with open(edge_file, \"wb\") as f:\n",
    "        f.write(\"from\\tto\\tweight\\tpaper\\n\")\n",
    "        for line in edge_list[0:50]:\n",
    "            f.write(line.encode('utf8'))\n",
    "            f.write(\"\\n\")\n",
    "    node_list = author_from_edgelist(edge_list[0:50])\n",
    "    \n",
    "    with open(node_file, \"wb\") as f:\n",
    "        f.write(\"ID\\tName\\tType\\n\")\n",
    "        for au in node_list[0:50]:\n",
    "            line = \"\\t\".join([au, authors[au].name, \"P\"])\n",
    "            f.write(line.encode('utf8'))\n",
    "            f.write(\"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_output(authors, papers, 2011, 2015, \"edges.txt\", \"nodes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Paper Network Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_au = []\n",
    "for au in authors.values():\n",
    "    out_au.append(au.__dict__)\n",
    "\n",
    "with open(\"./Data/Author_Data.json\", \"wb\") as f:\n",
    "    json.dump(out_au, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_pp = []\n",
    "for pp in papers.values():\n",
    "    out_pp.append(pp.__dict__)\n",
    "\n",
    "with open(\"./Data/Paper_Data.json\", \"wb\") as f:\n",
    "    json.dump(out_pp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./Data/Author_Data.pickle\", \"wb\") as f:\n",
    "    pickle.dump(authors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./Data/Paper_Data.pickle\", \"wb\") as f:\n",
    "    pickle.dump(papers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rake\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G=nx.path_graph(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_edgelist(G, \"test.edgelist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o = []\n",
    "for p in papers.values():\n",
    "    o.extend(p.topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
