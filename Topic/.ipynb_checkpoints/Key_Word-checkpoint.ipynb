{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Author():\n",
    "    def __init__(self, name, aid):\n",
    "        self.name = name\n",
    "        self.aid = aid\n",
    "        self.nicknames = []\n",
    "        self.paper_ids = []\n",
    "    \n",
    "    def add_paper(self, pid):\n",
    "        if pid not in self.paper_ids:\n",
    "            self.paper_ids.append(pid)\n",
    "            \n",
    "    def add_nickname(self, name):\n",
    "        if name not in self.nicknames:\n",
    "            self.nicknames.append(name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Paper():\n",
    "    def __init__(self, title, abstract, year, author_names, b_topic, topics, pid, detc, url):\n",
    "        \n",
    "        # Basic info\n",
    "        self.title = title\n",
    "        self.abstract = abstract\n",
    "        self.year = year\n",
    "        self.author_names = author_names\n",
    "        self.broad_topic = b_topic\n",
    "        self.topics = topics\n",
    "        self.pid = pid\n",
    "        self.detc = detc\n",
    "        self.url = url\n",
    "        \n",
    "        # add later\n",
    "        self.author_ids = []\n",
    "        self.citations = []\n",
    "        self.cited_by = []\n",
    "    \n",
    "    def add_author_id(self, aid):\n",
    "        if aid not in self.author_ids:\n",
    "            self.author_ids.append(aid)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Read papers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = \"../data/DAC_Entire_DataBase.json\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    database = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "papers = {}\n",
    "for p in database:\n",
    "    paper = Paper(p['Title'], p['Abstract'],p['Year'],p['Authors'], p['Broad_Topic'],\\\n",
    "                  p['Topics'], p['PaperID'],p['DETC'], p['URL'])\n",
    "    papers[paper.pid] = paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## add author into the dataset\n",
    "author_names = {}\n",
    "\n",
    "for p in papers.values():\n",
    "    for n in p.author_names:\n",
    "        author_names[n] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign IDs to each author\n",
    "\n",
    "id = 0\n",
    "for n in author_names.keys():\n",
    "    author_names[n] = str(id)\n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authors = {}\n",
    "\n",
    "for name in author_names.keys():\n",
    "    authors[author_names[name]] = Author(name, author_names[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_name_to_author_dict(authors):\n",
    "    ret = {}\n",
    "    for author in authors.values():\n",
    "        ret[author.name] = author\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "for p in papers.values():\n",
    "    text.append(p.abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rake\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rake_object = rake.Rake(\"SmartStoplist.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7d2e014b4dac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrake_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/erichsu/Documents/research/dac_network_research/Topic/rake.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0msentence_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mphrase_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_candidate_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__stop_words_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/erichsu/Documents/research/dac_network_research/Topic/rake.py\u001b[0m in \u001b[0;36msplit_sentences\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \"\"\"\n\u001b[1;32m     57\u001b[0m     \u001b[0msentence_delimiters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'[.!?,;:\\t\\\\\\\\\"\\\\(\\\\)\\\\\\'\\u2019\\u2013]|\\\\s\\\\-\\\\s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_delimiters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or buffer"
     ]
    }
   ],
   "source": [
    "keywords = rake_object.run(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Connection (between author and paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name2author = make_name_to_author_dict(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let each author has paper_id list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for paper in papers.values():\n",
    "    for name in paper.author_names:\n",
    "        author = name2author[name]\n",
    "        \n",
    "        author.add_paper(paper.pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let each paper has author_id list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for paper in papers.values():\n",
    "    for name in paper.author_names:\n",
    "        paper.add_author_id(name2author[name].aid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Name Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect similar name pairs\n",
    "\n",
    "Running the following cell will generate lines of similar names. Each line is formatted as \"author_id, name, author_id, name\". For each line, it the two are indeed similar, them copy and paste the line into data/disambiguation.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import Levenshtein\n",
    "keys = name2author.keys()\n",
    "\n",
    "for i in range(0, len(keys)):\n",
    "    for j in range(i+1, len(keys)):\n",
    "        p1 = name2author[keys[i]]\n",
    "        p2 = name2author[keys[j]]\n",
    "        \n",
    "        first = p1.name\n",
    "        second = p2.name\n",
    "        \n",
    "        pdist = fuzz.partial_ratio(first, second)\n",
    "        dist = Levenshtein.distance(first, second)\n",
    "        lv_ra = Levenshtein.ratio(first, second)\n",
    "        \n",
    "        if pdist >90 or dist <=2 or lv_ra >0.8:\n",
    "            print p1.aid+\"\\t\"+first+\"\\t\"+p2.aid+\"\\t\"+second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for merging name1 and name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge(id1, id2, authors, papers):\n",
    "    author1 = authors[id1]\n",
    "    author2 = authors[id2]\n",
    "    \n",
    "    # 1. On Author level\n",
    "    \n",
    "    # let 1 has 2's all paper_ids\n",
    "    for pid in author2.paper_ids:\n",
    "        author1.add_paper(pid)\n",
    "    \n",
    "    # make 2's name as 1's nickname\n",
    "    author1.add_nickname(author2.name)\n",
    "    \n",
    "    # 2. On Papers level\n",
    "    # Make author2's papers that contain author2.id now contain author1.id\n",
    "    for pid in author2.paper_ids:\n",
    "        paper = papers[pid]\n",
    "        paper.author_ids = [id1 if x == id2 else x for x in paper.author_ids]\n",
    "    \n",
    "    # remove id2\n",
    "    authors.pop(id2)\n",
    "    \n",
    "    print author1.name, \" AND \", author2.name, \"ARE MERGED!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from disambiguation file\n",
    "\n",
    "Think of these name pairs as edges in graph, we need to find connected components of that graph and each component is referring to a person's name set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.Graph()\n",
    "disamb_file_path = \"data/disambiguation.txt\"\n",
    "\n",
    "dependency = []\n",
    "with open(disamb_file_path, \"rb\") as f:\n",
    "    for line in f:\n",
    "        segs = line.strip().split(\"\\t\")\n",
    "        id1 = segs[0]\n",
    "        id2 = segs[2]\n",
    "        G.add_edge(int(id1), int(id2))\n",
    "\n",
    "names = [sorted(list(c)) for c in sorted(nx.connected_components(G), key=len, reverse=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name_list in names:\n",
    "    for i in range(0, len(name_list)-1):\n",
    "        idx = len(name_list) - 1 - i\n",
    "        merge(str(name_list[idx-1]), str(name_list[idx]), authors, papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authors['680'].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name2author['Kaarthic Madhavan'].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "papers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "papers['DETC2015-46822, pp. V02BT03A052'].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_author_node(author_list):\n",
    "    node_list = [\"id\\tname\"]\n",
    "    for author in author_list:\n",
    "        node_info = \"\\t\".join([author.aid, author.name])\n",
    "        node_list.append(node_info)\n",
    "    return node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_paper_node(paper_list):\n",
    "    node_list = [\"id\\ttitle\"]\n",
    "    for paper in paper_list:\n",
    "        node_info = \"\\t\".join([paper.pid, paper.title])\n",
    "        node_list.append(node_info)\n",
    "    return node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_to_file(info_list, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        for line in info_list:\n",
    "            f.write(line)\n",
    "            f.write(\"\\n\")\n",
    "    print filename, \"DONE!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Interpreter():\n",
    "    def __init__(self):\n",
    "        self.digit_holder = {}\n",
    "        self.string_holder = {}\n",
    "        \n",
    "    def add(self, key, value):\n",
    "        self.digit_holder[key] = value\n",
    "        self.string_holder[value] = key\n",
    "    \n",
    "    def lookup(self, key):\n",
    "        if type(key) is int:\n",
    "            return self.digit_holder[key]\n",
    "        else:\n",
    "            return self.string_holder[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_aid = Interpreter()\n",
    "fake_pid = Interpreter()\n",
    "\n",
    "for i in range(0, len(authors.keys())):\n",
    "    aid = authors.keys()[i]\n",
    "    fake_aid.add(i, aid)\n",
    "    \n",
    "for i in range(0, len(papers.keys())):\n",
    "    pid = papers.keys()[i]\n",
    "    fake_pid.add(i, pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pairs(input_list):\n",
    "    length = len(input_list)\n",
    "    ret = []\n",
    "    if length <= 1:\n",
    "        return []\n",
    "    for i in range(0, length-1):\n",
    "        for j in range(i+1, length):\n",
    "            ret.append((input_list[i], input_list[j]))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def author_network(authors, papers, start_year, end_year):\n",
    "    edge_list = [\"from\\tto\\tweight\\tpaper\"]\n",
    "    for p in papers.values():\n",
    "        if p.year < start_year or p.year > end_year:\n",
    "            continue\n",
    "        author_ids = p.author_ids\n",
    "        edges = make_pairs(author_ids)\n",
    "        for edge in edges:\n",
    "            edge_list.append(\"\\t\".join[edge[0], edge[1], \"10\", p.title])\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Paper Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rake\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G=nx.path_graph(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_edgelist(G, \"test.edgelist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o = []\n",
    "for p in papers.values():\n",
    "    o.extend(p.topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o = list(set(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"from\\tto\\tweight\\ttype\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
