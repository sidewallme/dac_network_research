title,Abstract,year
"PDE-Driven Level Sets and Shape Sensitivity for Structural Topology Optimization","This paper addresses the problem of structural shape and topology optimization. A level set method is adopted as an alternative approach to the popular homogenization based methods. The paper focuses on four areas of discussion: (1) The level-set model of the structure’s shape is characterized as a region and global representation; the shape boundary is embedded in a higher-dimensional scalar function as its “iso-surface.” Changes of the shape and topology are governed by a partial differential equation (PDE). (2) The velocity vector of the Hamilton-Jacobi PDE is shown to be naturally related to the shape derivative from the classical shape variational analysis. Thus, the level set method provides a natural setting to combine the rigorous shape variations into the optimization process. Finally, the benefit and the advantages of the developed method are illustrated with several 2D examples that have been extensively used in the recent literature of topology optimization, especially in the homogenization based methods.",2004
"An Efficient Feasibility Robust Optimization Method Using a Sensitivity Region Concept","We present a new robust optimization method that ensures feasibility of an optimized design when there are uncontrollable variations in design parameters. This method is developed based on the notion of a sensitivity region, which is a measure of how far a feasible design is from the boundary of a feasible domain in the parameter variation space. As the design moves further inside the feasible domain, and thus becoming more feasibly robust, the sensitivity region becomes larger. Our method is not sampling-based so it does not require a presumed probability distribution as input and is efficient in terms of function evaluations. In addition, our method does not use gradient approximation and thus is applicable to problems having non-differentiable constraint functions and large parameter variations. As a demonstration, we applied our method to an engineering example, the design of a control valve actuator linkage. In this example, we show that the method is efficient and the optimum design obtained is robust.",2004
"Numerical and Experimental Study of Shielding Gas Orientation Effects on Particle Stream Concentration Mode in Coaxial Laser Aided Material Deposition Process","Laser aided deposition quality largely depends on the powder stream structure below the nozzle. Modeling of the powder concentration distribution rarely relies on the numerical approach partially due to the complex phenomenon involved in the two-phase turbulence flow. In this paper, a numerical model is introduced to predict the particle-gas flow precisely and economically in order to meet the practical requirement for coaxial nozzle design optimizations. This model is able to quantitatively predict the powder stream concentration mode under different outer shielding gas directions and inner/outer gas velocity ratio. The numerical simulation results are compared with the experimental study using prototyped coaxial nozzles. The results are found to match. This study shows that the particle concentration mode is influenced significantly by the outer gas direction and gas flow settings.",2004
"Analysis of Decomposability and Complexity for Design Problems in the Context of Decomposition","The current practice in problem decomposition assumes that (1) design problems can be ",2004
"Freeform Feature Retrieval by Signal Processing","Feature retrieval is of great importance in shape modelling, in terms of supporting design reuse by obtaining reusable geometric entities. However, conventional techniques for feature retrieval are generally limited to the extraction of feature lines, curve segments, or surfaces, and the feature distortion imposed by feature interaction remains unconsidered. This paper investigates approaches for freeform feature retrieval by means of signal processing techniques. By treating features or regions of interest as surface signals, we employ digital filters to separate the feature signal from that of the domain surface, retrieving the “pure” feature from an existing shape model. Strategies for different model types are elaborated, for instance, the exact feature retrieval method designed for shape models with explicit data structure, such as B-Rep, or other accessible representations; and the signal filtering method for models with structured or unstructured data sets, such as that in mesh or point cloud models. Specifically, in the signal filtering method feature retrieval is implemented by the convolving operator in the frequency domain. By transforming the problem of shape decomposition from geometric extraction in the spatial domain to computation in the frequency domain, the proposed methods not only brings in significant computational efficiency, but also reduces the complexity of problem solving for feature retrieval. Provided examples show that the proposed approaches can achieve satisfactory results for simple geometries, whereas for sophisticated shapes guidelines for the design of dedicated filters are elaborated.",2004
"Covariance Modeling Method for Use in Compliant Assembly Tolerance Analysis","In assemblies involving compliant parts, springback and residual stress are caused when geometric variation in the assembly requires the parts be deformed to allow for assembly. A method is needed to predict the deformation due to the geometric variations. Researchers in the areas of Statistical Tolerance Analysis and Stochastic Finite Element Analysis have developed methods to account for statistical variation of parameters in a finite element model. A new statistical method uses an orthogonal polynomial-based covariance model to account for surface variation of the compliant parts over a wide range of wavelengths. The method has been demonstrated to match the accuracy of Monte Carlo simulation with a single calculation, and accurately model covariance data taken from real parts.",2004
"A Product Ontology for Automotive Seat Specification","A knowledge-based requirements management tool is being developed for the automotive industry to aid in the specification of modular systems whose development is contracted out to the supply chain. The aim of this tool is to allow the original equipment manufacturer (OEM) and their system suppliers to have a shared conceptualization of the product requirements. This paper highlights some of the issues with the current paper-based specifications and the use of natural language to represent the requirements. The framework of the knowledge-based tool in order to address these issues through the application of ontology is described. A ‘product’ ontology for the specification of the seating assembly for a car is presented. The ontology encapsulates the required functionalities, design parameters, performance criteria, structure and geometry. This is the result of the consensual convergence in the vocabulary, definitions and attributes that describe the product requirements.",2004
"Resistance Based Modeling of Collaborative Design","The paper presents a new model for collaborative design. The model is analogous to electrical circuits with current (rate of design artifact synthesis and analysis), voltage (knowledge that drives the design process), and resistance (barriers to the exchange of design information). The resistances are identified from a collaborative design taxonomy. This model is illustrated through a simple example. Extensions and an assessment of the model are provided.",2004
"An Optimization Study of the Ultrasonic Welding of Thin Film Polymers","In manufacturing industries, ultrasonic welding has established itself as one of the most effective techniques for fusing plastic assemblies due to its rapid performance and the absence of filler material. In this report, a thermoplastic polyurethane prototype of an orthopedics device that requires a hermetic seal is joined using ultrasonic welding. A robust design approach is used to study the manufacturing control factors that influence the process. The welding process factors and their interactions are used to characterize the resulting seal. Burst testing is used to assess weld strength. Optical microscopy in addition to SEM images, are used for a qualitative evaluation of the welded joint. Optimum process parameter settings from the robust design study deliver a strong and leak-proof weld.",2004
"A Method to Solve Inverse Kinematics Problems Using Lie Algebra and Its Application to Robot Spray Painting Simulation","This paper presents a new method for robot spray painting simulation. First, the authors introduce a method for rigid body motion interpolation proposed by Zefran for generating smooth trajectories of a spray gun. Second, the authors propose a method to solve inverse kinematics problems using Lie algebra for computing the motion of the robot manipulator from the spray gun’s motion. Third, the authors propose a method for calculation of color depth of the workpiece painted with the spray gun. Finally, in order to evaluate the usefulness of the three proposed methods, the authors develop a simulation system for robot spray painting.",2004
"Derivation of Design Guidelines for Miniature Machine Tools","As has been demonstrated the “microfactory”, which is a miniature manufacturing system proposed by the author and his research group, small machine tools that are comparable in size to their target products lead to large reductions in energy consumption and occupied space. They also increase the flexibility of system reconfiguration because of their low weight and small size. Although it had been thought that micro machine tools might not have sufficient metal cutting capability, experiments showed that were capable of micro mechanical fabrication. However, the design of miniature machine tools has not been fully optimized. For example, the design target of the first prototype, a performable miniature machine (“Micro lathe”), was to make the overall size as small as possible. The author proposed a design evaluation method to roughly estimate machine tool performances during its early design stage. In this paper, the above-mentioned design tool is applied to find suitable miniaturizing strategies. By applying the design tool to the miniaturization of machine tools, it is possible to determine which of the design candidates have the best theoretical performance and which of the local error factors would significantly affect machine performance. From the results of calculation, the tool can clarify the difference of effect of error sources on performances between normal machine tools and miniature machine tools. This leads to some suggestions regarding structures, sizes and suitable machine components. Design guidelines for miniature machine tools can be obtained from the information.",2004
"Automated Symmetry Exploitation in Engineering Analysis","It is well known that one can exploit symmetry to speed-up engineering analysis and improve accuracy, at the same time. Not surprisingly, most CAE systems have standard ‘provisions’ for exploiting symmetry. However, these provisions are inadequate in that they needlessly burden the design engineer with time consuming and error-prone tasks of symmetry detection, symmetry cell construction and reformulation. In this paper, we propose and discuss an automated methodology for symmetry exploitation. First, we briefly review the theory of point symmetry groups that symmetry exploitation rests on. We then address symmetry detection and ‘symmetry cell’ construction. We then address an important concept of boundary mapping of symmetry cells, and relate it to the irreducible representations of point symmetry groups. By formalizing these concepts, we show how automated symmetry exploitation can be achieved, and discuss an implementation of the proposed work within the FEMLAB CAE environment.",2004
"On the Design Synthesis of Multistable Equilibrium Systems","Multistable equilibrium (MSE) systems are a type of adaptable system that can have multiple mechanical configurations requiring no power to maintain the stable configurations. Thus, power is only needed to move among the stable states, and each stable configuration represents a level of adaptability. Since stable equilibrium configurations can be defined by potential energy minima, we base the design of MSE systems on shaping the potential energy curve at desired equilibrium configurations. This view allows one to construct a performance space defined by how well candidate systems meet a desired potential energy curve. By using a Monte Carlo mapping to link the performance space to the design space in tandem with stochastic optimization methods, the designer determines whether or not a certain system topology can be designed as a MSE system. Qualitative and quantitative mapping procedures enable the designer to decide whether or not the desired design lies near the center or periphery of a performance space. This dictates how the optimization is to be executed which in turn informs the designer as to whether or not a feasible limit in the system performance has indeed been reached.",2004
"Optimization of a Semi-Active Shock Absorber Using a Genetic Algorithm","We propose an optimization method for a semi-active shock absorber for use in aircraft landing gear using Carroll’s FORTRAN Genetic Algorithm (GA) Driver. This method is compared with Powell’s conjugate direction method, a nonlinear programming (NP) approach, which uses not gradients, but only function values. In these optimizations, we handle variations in the maximum vertical acceleration of an aircraft during landing caused by the variation of the aircraft mass due to variations in the number of passengers and the amounts of cargo and fuel. The maximum vertical acceleration of an aircraft is set as an objective function to be minimized. Design variables searched in the first step of this optimization are discrete orifice areas formed by the outer surface of a hollow metering pin and a hole in the semi-active shock absorber. The design variable searched in the second step is an orifice area which is controlled based on the mass variation. For the GA runs, the ratio of the total number of optimum and near-optimum solutions to the total number of runs was greater than that for the NP runs. In addition, for the total GA runs, the total number of function evaluations per total number of optimum and near-optimum solutions was greater than that for the total NP runs. The optimum semi-active shock absorber is compared to the optimum passive shock absorber with respect to the variation of the acceleration of the aircraft mass. The ratio of maximum acceleration in the semi-active shock absorber to that in the passive shock absorber is 0.79 when the mass ratio is 0.65 maximum mass and is 0.58 when the mass ratio is 0.31 maximum mass.",2004
"Concurrent Parameter Design Based on Constraint Network","A Concurrent Parameter Design (CPD) based on constraint network method is proposed. Since concurrent design emphasizes solving downstream problems early in the design period, the constraint network, which is used to collect the constraints from the multidisciplinary teams, uses the consistency algorithm to verify the design process early in the process and to assist the designers in determining design variables to reduce the multidisciplinary iterations in concurrent design. A consistency algorithm which is designed using interval arithmetic to refine the intervals is used to obtain a feasible solution space for the designers. Then, the designers choose the parameters in the solution space using their expertise. The constraint network can reduce the modification iterations among the multidisciplinary teams during the concurrent design. The quantitative effect of the downstream constraints can be analyzed before determining the design parameters and potential conflicts can be predicted. A parameter design example about Bogie of Railway Rolling Stock is given to show the validity of the method.",2004
"A Quantitative Analysis of the Evolution of Design Automation Conference Fields","A quick look to the literature related to “Design” points out the fact that traditional fields are covered by a huge quantity of concepts and sub-topics dealing with various research fields. Some of these fields and related concepts are emerging and others are disappearing. The last two decades provided a large variations in the covered fields—probably because of the computers capacity and the knowledge sharing using the internet- We are convinced that is time now for a global understanding of the evolution of the related preoccupations in order to start a new phase that deals with the next guidelines issues in design. Many researchers and gurus have proposed evolution schemes from an epistemological point of view. However, we believe that we still need a pragmatic analysis of what have been done and what is going on now in the various publications that deals with design, conferences and journals. To do so, we present in this paper an approach that lies on the systematic analysis of the International Design Engineering Technical Conference (IDETC-ASME), the Design Conference, the Integrated Design and Manufacturing in Mechanical Engineering (IDMME) and the International Conference in Engineering Design (ICED). We also consider the major reviews and journals related to design such as Computer-Aided Design, Journal of mechanical design and many others. Our proposition, presents a global overview that shows the time-evolution of the topics, the density production, the emerging areas and concepts. We show then that some topics remain with a great interest and other are in a decreasing period. A specific study of what is going on within the Design Automation Conference is provided and an open discussion is started.",2004
"Optimization of Chemical Etching Process in Niobium Cavities","Superconducting niobium cavities are important components of linear accelerators. Buffered chemical polishing (bcp) on the inner surface of the cavity is a standard procedure to improve its performance. The quality of bcp, however, has not been optimized well in terms of the uniformity of surface smoothness. A finite element computational fluid dynamics (cfd) model was developed to simulate the chemical etching process inside the cavity. The analysis confirmed the observation of other researchers that the sections closer to the axis of the cavity received more etching than other regions. A baffle was used by lanl personnel to direct the flow of the etching fluid toward the walls of the cavity. A new baffle design was tined using optimization techniques. The redesigned baffle significantly improves the performance of the etching process. To verify these results an experimental setup for flow visualization was created. The setup consists of a high speed, high resolution ccd camera. The camera is positioned by a computer-controlled traversing mechanism. A dye injecting arrangement is used for tracking the fluid path. Experimental results are in general agreement with computational findings.",2004
"An Efficient Weighting Update Method to Achieve Acceptable Consistency Deviation in Analytical Target Cascading","Weighting coefficients are used in Analytical Target Cascading (ATC) at each element of the hierarchy to express the relative importance of matching targets passed from the parent element and maintaining consistency of linking variables and consistency with designs achieved by subsystem child elements. Proper selection of weight values is crucial when the top level targets are unattainable, for example when “stretch” targets are used. In this case, strict design consistency cannot be achieved with finite weights; however, it is possible to achieve arbitrarily small inconsistencies. This article presents an iterative method for finding weighting coefficients that achieve solutions within user-specified inconsistency tolerances and demonstrates its effectiveness with several examples. The method also led to reduced computational time in the demonstration examples.",2004
"A Comparison of Commonality Indices for Product Family Design","Today’s highly competitive and global marketplace is redefining the way companies do business: many companies are being faced with the challenge of providing as much variety as possible for the market with as little variety as possible between products. In order to achieve this, product families have been developed, allowing the realization of a sufficient variety of products to meet the customers’ demands while keeping costs relatively low. The challenge when designing a family of products is in resolving the tradeoff between product commonality and distinctiveness: if commonality is too high, products lack distinctiveness, and their individual performance is not optimized; on the other hand, if commonality is too low, manufacturing costs will increase dramatically. Toward this end, several commonality indices have been proposed to assess the amount of commonality within a product family. In this paper, we compare and contrast six of the commonality indices from the literature based on their ease of data collection, repeatability and consistency. Eight families of products are dissected and analyzed, and the commonality of each product family is computed using each commonality index. The results are then analyzed and compared, and recommendations are given on their usefulness for product family design. This study lays a foundation for understanding the relationship between different platform leveraging strategies and the resulting degree of commonality within a product family.",2004
"A System Approach to Simulation-Based Design Under Uncertainty, Through Best in Class Simulation Process Integration and Design Optimization","The importance of design robustness and reliability is a well-established notion and practice in today’s industry. Manufacturing companies strive to achieve Six-Sigma quality measures. While Virtual Prototyping is a key-factor in accelerating the product development process while reducing development costs, it has not contributed in the quest for improved product reliability and robustness performance since it is based on deterministic approaches. This paper provides a systematic approach to design for six-sigma simultaneously addressing variability and uncertainty present in real life on most design parameters. An example from the automotive industry illustrates the methodologies.",2004
"A Comparative Study of Constraint Programming Techniques Over Intervals in Preliminary Design","Three families of methods coexist for managing uncertainty (i.e. representing and propagating) of the product data during the preliminary design stages, namely: fuzzy methods, probabilistic methods and Constraint Programming (CP) methods. CP methods over reals are, up to now, the least frequently used approaches but they are worth being studied further for a use in design engineering thanks to a number of satisfactory properties and to recent significant advances. They may be roughly considered as a collection of methods that are sophisticated evolutions of interval analysis. The objective of this paper is to assess four of these major methods (namely the {",2004
"Front Structure Design Procedure for Optimal Pedestrian Leg Impact Performance","This paper describes a procedure to optimize the front structure of a vehicle for improved performance in the leg impact portion of pedestrian safety regulations proposed by the European Enhanced Vehicle-Safety Committee (EEVC). The first step in this procedure was to perform a simulation of the EEVC leg impact test with detailed finite element models of the EEVC leg impactor and the baseline design of a vehicle front structure. Next, a simplified, parametric finite element model of the vehicle front structure was used with the leg impactor model to simulate the leg impact test, and the results were correlated to the detailed finite element model and the test results. The leg impact simulation with the parametric vehicle model was then incorporated into an optimization procedure developed within the optimization code ISIGHT. In this procedure the parameters that controlled the vehicle geometry and structural stiffness in the simplified model were altered by ISIGHT to improve performance in the leg impact test.",2004
"A Recursive, Line-Intersection Method for Finding the Area of a Mesh Projected Onto a Plane","In this paper, we describe a new approach for computing the area of a mesh projected onto a plane. This approach utilizes the graphics hardware’s line/object intersection capability and a recursive subdivision strategy to achieve performance and precision control. This approach starts from digitizing the projection plane into a grid of rectangular elements. For each element the graphics engine is utilized to check whether projection lines passing through the nodes of the element intersect the object in the model space. If all lines intersect the object, the element is considered “inside” and its area will be accounted towards the final projection area. If none of the lines has an intersection, the element is considered “outside” and discarded. For those elements that lay along the boundary of the projected area (which means some of their lines intersect the model while others don’t) we subdivide them until they are sufficiently small and the given area tolerance is met. Heuristics are derived for deciding the initial grid resolution and the level of subdivisions needed to meet/exceed a given area tolerance. Implementation results are demonstrated and compared with a classic polygon-clipping approach.",2004
"Task Scheduling of Parallel Development Projects Using Genetic Algorithms","Resources for development projects are often scarce in the real world. Generally, many projects are to be completed that rely on a common pool of resources. Besides resource constraints, there exists data dependency among tasks within each project. A genetic algorithm approach with one-point uniform crossover and a refresh operator is proposed to minimize the overall duration or makespan of multiple projects in a resource constrained multi project scheduling problem (RCMPSP) without violating inter-project resource constraints or intra-project precedence constraints. The proposed GA incorporates stochastic feedback or rework of tasks. It has the capability of capturing the local optimum for each generation and therefore ensuring a global best solution. The proposed Genetic Algorithm, with several variants of GA parameters is tested on sample scheduling problems with and without stochastic feedback. This algorithm demonstrates to provide a quick convergence to a global optimal solution and detect the most likely makespan range for parallel projects of tasks with stochastic feedback.",2004
"Dynamic Modeling and Simulation of Parallel Kinematic Machines","This paper presents an effective method for inverse dynamic modeling of a five-axis milling machine with parallel kinematic chains (PKM). For solving the inverse dynamics, the methodology of using the principle of virtual work is introduced, which corrects a theoretic error in formulating the dynamic equations of motions sound in previous literatures. A corresponding computational algorithm for solving the inverse dynamics of the parallel kinematic machine is given and two cases of motion trajectories are calculated to check the proposed method. The corrected dynamic modeling is robust and features higher computational efficiency than other dynamic modeling methods such as recursive Newton-Euler method or Lagrangian formulations. Using this dynamic modeling and simulation method, we can anticipate the dynamic behavior of the five-axis machine and develop a suitable algorithm for motion control and dynamic optimization.",2004
"DRed and Design Folders: A Way of Capturing, Storing and Passing On Knowledge Generated During Design Projects","This paper describes a software tool called DRed (the D esign R ationale ed itor), that allows engineering designers to record their design rationale (DR) at the time of its generation and deliberation. DRed is one of many proposed derivatives of the venerable IBIS concept, but by contrast with other tools of this type, practicing designers appear surprisingly willing to use it. DRed allows the issues addressed, options considered, and associated arguments for and against, to be captured graphically. The software, despite still being essentially a research prototype, is already in use on high profile design projects in an international aerospace company, including the presentation of results of design work to external customers. The paper compares DRed with other IBIS-derived software tools, to explain how it addresses problems that seem to have made them unsuitable for routine use by designers. In addition to the capture and presentation of the DR itself, the set of linked DR graphs can be used to provide a map of the contents of an electronic Design Folder, containing all the documents created by an individual or team during a design project. The structure of the knowledge model instantiated in such a Design Folder is described. By reprising a design case study published at the DTM 2003 conference, concerning the design of a Mobile Arm Support (MAS), the DRed knowledge model is compared with the previously proposed Design Data Model (DDM), to show how it addresses the shortcomings identified in the DDM. Finally the methodology and results of the preliminary evaluation of the use of DRed by aerospace designers are presented.",2004
"Identifying and Tracking Features in Freeform Shape","Building a smooth and well structured surface to fit unstructured 3-D data is always an interesting topic in Computer-Aided Design (CAD). In this paper, a method of approximating complex freeform shapes with parameterized freeform feature templates is proposed. To achieve this, a portion of a digitized 3-Dimensional (3-D) shape should be matched, or fitted, to a deformable shape feature template, where the deformation is a function of intrinsic feature parameters. 3-D shape matching to, possibly sparse, inaccurate or otherwise degraded, freeform surface data is known to be hard. Using a variant of the directed Hausdorff distance measure of shapes, it is shown that convergence towards a shape match is feasible. Based on sensitivity analyses of the shape distance measures, it is determined that adjusting coefficients of the optimization function in different stages of optimizations can accelerate the optimization procedure. By the matching results, a standard deviation-like function is proposed to achieve automatic feature recognition. With the proposed extendable concept, complex freeform shapes are tracked and fitted automatically. Based on a defined interference ratio, interfered feature can also be identified. Numerical experiments were conducted in order to verify the proposed method and to find the maximal degree of feature interference for which matching is successful. It is also described how the presented technique can be applied in shape modeling applications.",2004
"Development of a Production Cost Estimation Framework for Product Family Design","The main task of a product family designer is to decide the right components/design variables to share among products to maintain economies of scale with minimum sacrifice in the performance of each product in the family. The decisions are usually based on several criteria, but production cost is of primary concern. Estimating the production cost of a family of products involves estimating the production cost of each product in the family including the cost effects of common and variant components/design variables in the family. In this paper, we introduce a production cost estimation framework for product family design based on Activity-Based Costing (ABC), which is composed of three stages: (1) allocation, (2) estimation, and (3) analysis. In the allocation stage, the production activities that are necessary to produce all of the products in the family are identified and modeled with an activity table, a resource table, and an activity flow. To allocate the activities to products, a product family structure is represented by a hierarchical classification of the items that form the product family. In the estimation stage, production costs are estimated by converting the production activities to costs using key cost drivers that consume main resources. In the analysis stage, components/design variables for product family design are investigated with resource sharing methods through activity analysis. As an example, the proposed framework is applied to estimate the production cost of a family of cordless power screwdrivers.",2004
"Modeling and Design of Materials for Controlled Wave Propagation in Plane Grid Structures","Formulations for the optimal design of plane grids with maximum band gaps are presented. Periodic band-gap structures prevent waves in certain frequency ranges from propagating. Materials or structures with band gaps have many applications, including frequency filters, vibration protection devices and wave guides. Here, a simple model of a periodic plane grid structure is presented and then an optimization problem is formulated where the structure’s band gap above a particular frequency is maximized by the selective addition of non-structural masses. Numerical implementation issues are discussed and examples are presented.",2004
"An Efficient Pareto Set Identification Approach for Multi-Objective Optimization on Black-Box Functions","Both multiple objectives and computation-intensive black-box functions often exist simultaneously in engineering design problems. Few of existing multi-objective optimization approaches addresses problems with expensive black-box functions. In this paper, a new method called the Pareto set pursing (PSP) method is developed. By developing sampling guidance functions, this approach progressively provides a designer with a rich and evenly distributed Pareto optimal points. This work describes PSP in detail with analysis of its properties. From testing and design application, PSP demonstrates considerable efficiency, accuracy, and robustness. Theoretical proof of convergence of PSP is also given. It is believed that PSP has a great potential to be a practical tool for multi-objective optimization problems.",2004
"Ant Colony Optimization Method for Product Platform Formation","Product platform concepts are often deployed to achieve product variety and hence effective product customization. One of the popular methods to achieve product variety is to ",2004
"The Effects of Different Specifications on the Tolerance-Maps for an Angled Face","A new mathematical model for representing geometric tolerances is applied to a part with an angled face and is extended to show its sensitivity to different specifications for dimensioning and tolerancing the part. The model is compatible with the ASME/ISO Standards for geometric tolerances. Central to the new model is a Tolerance-Map® , a hypothetical volume of points that corresponds to all possible locations and variations of a segment of a plane which can arise from tolerances on size, position, form, and orientation. Every Tolerance-Map is a convex set. This model is one part of a bi-level model that we are developing for geometric tolerances. The new model makes stackup relations apparent in an assembly, and these can be used to allocate size and orientational tolerances; the same relations also can be used to identify sensitivities for these tolerances. All stackup relations can be met for 100% interchangeability or for a specified probability. This paper develops several Tolerance-Maps for a part with an angled end face for different tolerance specifications. These specifications are linear size, angularity, angular size, “linear size & angularity” and “linear & angular size” tolerance. Comparison of Tolerance-Maps for their content for these specifications led to the following conclusions: a) only angular size tolerance is not sufficient for tolerancing an angled face; b) if the value of tolerance remains the same, the allowable variation is more in a part having only an angularity tolerance than in one having only a size tolerance.",2004
"Development of Process Optimization for an Intelligent Knowledge-Based System for Spur Gear Precision Forging Die Design","Forging sequence design is mainly carried out using empirical rules for the design of the intermediate die shapes, in addition to many trail-and-error runs resulting in prolonged development times and higher costs. An integrated optimal design of preform shapes and process conditions approach to minimize the energy required is essential. The research presented in this article aims at developing an optimization algorithm to determine the optimum intermediate die shape-designs that minimize the total energy required during the forging process sequence. It is based on the results obtained in the previous research with focus on knowledge base and database representation to design precision forging solid gears and provide detailed process specification. A three-step algorithm, which addresses gear construction design, manufacturability analysis of gear construction and die-design optimization, is used to generate the parametric gear model and automatically extract design information for manufacturing process planning based on the feature-based parametric design system. Utilization of the shape optimization method for preform stages avoids costly production problems. The optimized approach provides accurate description of all stages involved in the forging process. Forging load and energy required, along with metal flow and detailed geometry specification of die forms for every forging stage are obtained. The forging energy requirements based on this approach are as much as 25% lower than those arrived from die designs based on actual tooth profile geometry.",2004
"Global Stiffness Improvement for Tricept Machine Tools Family","In this paper, an alternate passive leg structure is proposed for Tricept machine tool to form a modified Tricept machine tool. The global stiffness of the modified Tricept is derived and compared with that of the Tricept machine tool. First, the configurations of the Tricept and modified Tricept are introduced respectively. Then, the global velocity equations are derived and the stiffness models of the two configurations are presented and analyzed. Finally, the advantages and disadvantages of the two types of passive leg structure are analyzed and concluded and stiffness simulations are conducted.",2004
"A Parametric Approach to Vehicle Seating Buck Design","Vehicle package development is an important part of the entire vehicle design. It consists of determining the occupant’s spatial environment, the vehicle’s mechanical spatial configuration and the overall exterior/interior dimensions while meeting the engineering requirements, including packaging, structure, manufacturing, etc. Developing and verifying the occupant compartment configuration is usually conducted by using a seating buck. To build a seating buck, vehicle interior surfaces are generated in CAD using vehicle exterior surfaces, package layouts and master sections. During early program stages, this information is scattered, incomplete and constantly changing, which makes the seating buck creation challenging and the package design decision-making more difficult. A new method has been developed to quickly generate the seating buck surfaces from scattered information. It has shown to significantly reduce the time conventionally required for the seating buck surface modeling. This paper documents the method and process and summarizes the potential of the method and its impact on vehicle package design.",2004
"Parameter and Tolerance Constraints Modeling for Assembly","Geometric parameter and tolerance design are two important phase in product design, and will affect the assembly functionality of the product. The aim of the article is to present a new method of parameter and tolerance constraints modeling for assembly. In the nominal domain, a graphical representation of the linkage of geometric constraints is termed the nominal loop circuit (NLC), which helps to formulate the stack path of parameters into parameter equations. In the variational domain, assembly stackup functions are established. In the tolerance domain, tolerance inequations are formulated. The parameter equations, tolerance inequations and assembly stackup functions constitute parameter and tolerance constraints model, which can be used to optimize of parameter and tolerance. The method is demonstrated by a gear pump design problem.",2004
"Fully Free-Form Deformation Features Incorporating Discontinuities",,2004
"Design of Components With Optimized Microstructure","The ability to optimize shape and microstructure creates tremendous potential for designing lightweight high-performance structural components, but this potential can only be realized if design procedures are effectively linked to fabrication techniques. In this paper we describe such links. The key to this work is to base the topology optimization on a unit cell that matches the physical unit cell used in the fabricated object. Distortion and rotation of the unit cell can control effective material properties at all locations within the component by affecting changes in density, degree of anisotropy, and orientation of principle material axes. Advances in solid freeform fabrication (SFF) and related hybrid fabrication techniques make production of components with complex microstructures feasible. This paper describes the complete design process, from specializations of topology optimization to interpretation of optimization results and communication of design information to SFF machines. The process includes a new procedure to establish the orientation of an orthotropic material for multiple loading cases.",2004
"An Integrated Design Support Environment for a Micro-Scale Portable Absorption Cooling System","Portable cooling systems play an important role in assisting human operations in unfriendly environments, such as soldiers continuously working in a desert area for long hours. Typical cooling system designs utilizing a vapor compression cycle driven by electrical power usually have high weights due to batteries and as a result, compromise the effectiveness of the portable cooling system. A self-contained absorption cycle cooling system design based on micro-scale thermal technology has demonstrated unique advantages in minimizing system weight while providing reasonable thermal efficiency. This system adopts a heat actuated absorption/desorption thermal cycle to raise the pressure of the refrigerant vapor without a heavy battery load. Design challenges exist: 1) multi-physics considerations when integrating the thermodynamic and transport models for the heat pump and peripheral component devices; 2) trade-off among multi-functional design requirements of system weight and thermal efficiency, using the inputs of cooling load, heat rejection temperature, and heat transfer characteristics based on the micro-channel geometry. No existing design automation tools are available on the market to directly support these design tasks. In this work, physics-based system-level models are developed and validated against state-of-the-art prototypes. The use of these models is demonstrated through the design of a 150-watt portable cooling system, typically used by the military in desert training. The system modeling methodology is implemented in Java as a part of an Integrated Design Support Environment, and has been used to generate trade-off study results. These results show that the current implementation is effective, and is a significant step toward a complete integrated design support environment to analyze and synthesize high-quality micro-scale portable cooling systems.",2004
"A Conceptual Design Synthesis Framework for Micro-Electro-Mechanical Systems (MEMS)","It is well recognized that conceptual design is the most critical stage of product development process. Yet, existing MEMS (Micro-Electro-Mechanical Systems) design synthesis models or methods are very restrictive in supporting MEMS conceptual design, in that they are only applicable to specific or specific types of designs, where building blocks for design synthesis have to be pre-specified by the designers. To address this problem, this paper proposes a MEMS conceptual design synthesis framework, which consists of a behavior representation that caters for the multidisciplinary MEMS design characteristics and a design synthesis strategy that is able to explore multidisciplinary phenomena for the development of MEMS initial design concepts. The behavior representation incorporates information of both physical interactions and chemical/biological/other reactions that take place during a MEMS device’s behavioral process. The design synthesis is accomplished by both forward and backward synthetic search strategies in identifying the relevant phenomena for the development of the desired behavioral processes. The framework can be used to develop both the physical structure of a MEMS device and the substances that are necessary for the chemical/biological/other reactions. A software prototype implementing the proposed framework is also presented, followed by a MEMS design case study.",2004
"A Survey of the Study of Failure","2003 was a year that a number of accidents broke out in Japan. The sudden increate in accidents and troubles had the people wonder if there is something fundamentally wrong with the way they are running the business. These series of accidents and failure brought much attention to the Study of Failure. The Study of Failure was first published in 1996 and gained national attention in 2000, however, its roots are found in the late 70s. This paper is intended to provide background information about the Study of Failure, where it came from what efforts are underway in Japan. Instead of making precise records of what happened, the Study of Failure concentrates on finding the root cause, which often times is organizational rather than individual, provides ways for effectively recording them and analyzing them so other people can receive the maximum benefit from learning about the events. It has no intention of accusing persons who may have caused the events. There are now publicly available databases and privately developed software based on the studies. The government is putting efforts into educating the people about these subjects.",2004
"A Knowledge-Based System for Change Impact Analysis","Due to the increasing complexity of the modern industrial context in an evolutionary environment, several changes (e.g. new technology, new system, human errors, etc.) may affect road safety. Analyzing the change impact on design requirements is a complex task especially when it deals with complex systems such as Vehicle Safety Systems (VSS). To handle a change impact analysis in road safety field, VSS designers require a specific knowledge stemmed from accidentology. In this paper, we develop a multi-view model of the road accident, which is crucial to extract the required knowledge. Indeed, this multi-view model allows the analysis of the impact of a given change on the Driver-Vehicle-Environment system from different viewpoints and on different grain of size. This allows an efficient approach to detect exhaustively the perturbations due to the change and thereby to anticipate and handle their effects. We use a Knowledge Engineering approach to implement the multi-view model in a Knowledge-Based System providing accidentologists and VSS designers with an efficient tool to carry out an analysis of change impact on analysis design requirements.",2004
"Evaluation Method for the Topological Synthesis of Sheet Metal Components","The popularity of sheet metal in modern engineering artifacts is due to the fact that it is both inexpensive as a raw material and inexpensive to form into components. In comparison to forging or machining components, sheet metal can produce lightweight and inexpensive design solutions. The main shortcomings of sheet metal are that resulting components have a limited rigidity and the feasibility of the parts is constrained by the inherent two-dimensionality of the initial sheet. Furthermore, design and manufacturing engineers are challenged by finding a shape that satisfies all spatial constraints and by deciding the optimal sequence of operations for making this product that minimizes both time and associated manufacturing costs. In the past two years, we have been working towards an automated tool that creates candidate sheet metal topologies and optimizes them for spatial constraints as well as time and cost objectives. While we have yet to complete this goal, we have to date developed a representation capable of creating a wide variety of sheet metal topologies (see DETC2002/DAC-34087) and have recently created a thorough evaluation method which is presented in this paper along with some preliminary results.",2004
"A Single-Loop Method for Reliability-Based Design Optimization","Reliability-Based Design Optimization (RBDO) can provide optimum designs in the presence of uncertainty. It can therefore, be a powerful tool for design under uncertainty. The traditional, double-loop RBDO algorithm requires nested optimization loops, where the design optimization (outer) loop, repeatedly calls a series of reliability (inner) loops. Due to the nested optimization loops, the computational effort can be prohibitive for practical problems. A single-loop RBDO algorithm is proposed in this paper for both normal and non-normal random variables. Its accuracy is the same with the double-loop approach and its efficiency is almost equivalent to deterministic optimization. It collapses the nested optimization loops into an equivalent single-loop optimization process by imposing the Karush-Kuhn-Tucker optimality conditions of the reliability loops as equivalent deterministic equality constraints of the design optimization loop. It therefore, converts the probabilistic optimization problem into an equivalent deterministic optimization problem, eliminating the need for calculating the Most Probable Point (MPP) in repeated reliability assessments. Several numerical applications including an automotive vehicle side impact example, demonstrate the accuracy and superior efficiency of the proposed single-loop RBDO algorithm.",2004
"Geometric Design of Uniform Developable B-Spline Surfaces","This paper studies geometric design of uniform developable B-spline surfaces from two boundary curves. The developability constraints are geometrically derived from the de Boor algorithm and expressed as a set of equations that must be fulfilled by the B-spline control points. These equations help characterize the number of degrees of freedom (DOF’s) for the surface design. For a cubic B-spline surface with a first boundary curve freely chosen, five more DOF’s are available for a second boundary curve when both curves contain four control points. There remain (7-2m) DOF’s for a cubic surface consisting of m consecutive patches with C2  continuity. The results are in accordance with previous findings for equivalent composite Bézier surfaces. Test examples are illustrated to demonstrate design methods that fully utilize the DOF’s without leading to over-constrained systems in the solution process. Providing a foundation for systematic implementation of a CAGD system for developable B-spline surfaces, this work has substantial improvements over past studies.",2004
"Creative Design, Issues and Strategies","In this paper, three points are emphasized to cope with computational creative design, decomposition, mapping and reconstitution (D-M-R for short), which is proposed to cope with divergent exploration, automatic transformation and convergent exploitation. It could be concluded that, management of creative process is the key issue to develop creative computational design tools; and the modeling of design tools could facilitate the creative thought processes. Although creative work need the tension between building and breaking out of intellectual traditions, the creative activity in CAD systems need large knowledge base to support design activities and is capable of learning. The decomposition, mapping and reconstitution model could be a common exploration, transformation and exploitation procedure for management of computational design tools, therefore helpful for creative work; specifically packages of design tools have been developed to testify creativity in design practices, and the relationship between creativity and automation.",2004
"A Saddlepoint Approximation Method for Uncertainty Analysis","The availability of computationally efficient and accurate methods for probabilistic computation is crucial to the success of applications of probabilistic design using complex engineering simulation models. To address this need, a Saddlepoint Approximation method for probabilistic engineering analysis is introduced. A general performance function is approximated at the Most Likelihood Point with either linear or quadratic forms and the Saddlepoint Approximation is then applied to evaluate the probability associated with the performance. The proposed approach provides highly accurate probabilistic results while maintaining minimum computational requirement. Two examples are presented to demonstrate the effectiveness of the proposed method.",2004
"Geometric Containment Analysis for Rotational Parts","This paper describes a system and underlying algorithms to perform geometric containment analysis to determine if a newly designed rotational part can be manufactured from a part in an existing database of rotational parts. Only material removal of the database part is considered in order to obtain the newly designed part from the database part. The system uses a three-step algorithm to test for containment. The first step analyzes feasibility of containment using bounding cylinders. If the bounding cylinder of the query part is bigger than the part in the database, then the database part cannot contain the query part and it is eliminated from consideration. The second step analyzes feasibility of containment by ignoring off-axis features. Any part that fails to satisfy containment at this stage is eliminated from consideration. The third step analyzes the remaining parts from the database for feasibility of containment by including the off-axis features. Finally, the system rank-orders all the database parts that can contain the query part based on their volume differences with the query part. The system described in this paper can be used to find an existing part from which to manufacture a newly designed part. This capability is expected to significantly reduce proliferation of parts, to improve manufacturing responsiveness, and to reduce the cost of new products.",2004
"Integrating Freeform and Feature-Based Fitting Methods","Reverse engineering (RE) is the process of defining and instantiating a model based on the measurements taken from an exemplar object. Traditional RE is costly, requiring extensive time from a domain expert using calipers and/or coordinate measurement machines to create new design drawings/CAD models. Increasingly RE is becoming more automated via the use of mechanized sensing devices and general purpose surface fitting software. This work demonstrates the ability to reverse-engineer parts by combining feature-based techniques with freeform surface fitting to produce more accurate and appropriate CAD models than previously possible.",2004
"A Systems Framework for Platform Architecture Analysis","This paper discusses a systems framework for platform architecture analysis. The framework considers architectural analysis at three levels; the individual product offerings within a product family, the platform(s) being leveraged across the family, and the evolution potential for the platform/product family. The framework is decomposed into elements that consider a systems perspective: function, form, concepts, interfaces, needs/goals, upstream and downstream influences, and timing/operation. An application of the framework to a transport refrigeration product family is presented as a case study. The results of this case study indicate that the framework is promising, and it continues to be developed and applied within UTC.",2004
"On the Use of Kriging Models to Approximate Deterministic Computer Models","The use of kriging models for approximation and metamodel-based design and optimization has been steadily on the rise in the past decade. The widespread usage of kriging models appears to be hampered by (1) the lack of guidance in selecting the appropriate form of the kriging model, (2) computationally efficient algorithms for estimating the model’s parameters, and (3) an effective method to assess the resulting model’s quality. In this paper, we compare (1) Maximum Likelihood Estimation (MLE) and Cross-Validation (CV) parameter estimation methods for selecting a kriging model’s parameters given its form and (2) and an R2  of prediction and the corrected Akaike Information Criterion for assessing the quality of the created kriging model, permitting the comparison of different forms of a kriging model. These methods are demonstrated with six test problems. Finally, different forms of kriging models are examined to determine if more complex forms are more accurate and easier to fit than simple forms of kriging models for approximating computer models.",2004
"Decomposition-Based Assembly Synthesis of Space Frame Structures Using Joint Library","This paper presents a method for identifying the optimal designs of components and joints in the space frame body structures of passenger vehicles considering structural characteristics, manufacturability and assembleability. Dissimilar to our previous work based on graph decomposition, the problem is posed as a simultaneous determination of the locations and types of joints in a structure and the cross sections of the joined structural frames, selected from a predefined joint library. The joint library is a set of joint designs containing the geometry of the feasible joints at each potential joint location and the cross sections of the joined frames, associated with their structural characteristics as equivalent torsional springs obtained from the finite element analyses of the detailed joint geometry. Structural characteristics of the entire structure are evaluated by finite element analyses of a beam-spring model constructed from the selected joints and joined frames. Manufacturability and assembleability are evaluated as the manufacturing and assembly costs estimated from the geometry of the components and joints, respectively. The optimization problem is solved by a multi-objective genetic algorithm using a direct crossover. A case study on an aluminum space frame (ASF) of a middle size passenger vehicle is discussed.",2004
"A New Approach for Simultaneous Shape and Topology Optimization Based on Implicit Topology Description Functions","In the present paper, a new approach for structural topology optimization based on implicit topology description function (TDF) is proposed. TDF is used to describe the shape/topology of a structure, which is approximated in terms of the nodal values. Then a relationship is established between the element stiffness and the values of the topology description function on its four nodes. In this way and with some non-local treatments of the design sensitivities, not only the shape derivative but also the topological derivative of the optimal design can be incorporated in the numerical algorithm in a unified way. Numerical experiments demonstrate that by employing this approach, the computational efforts associated with TDF (and level set) based algorithms can be saved. Clear optimal topologies and smooth structural boundaries free from any sign of numerical instability can be obtained simultaneously and efficiently.",2004
"On Electrochemical Deposition for Layered Manufacturing","This paper describes the initial results from new research in the area of electrochemical deposition applied to rapid layered manufacturing with heterogeneous materials. Our interest in electrochemical layered manufacturing stems from earlier collaborative projects on heterogeneous modeling and fabrication [1–4]. The current work focuses on employing electrochemical deposition of binder into layers sequentially added to a powder bed as a method for additive fabrication of working parts. We show that electrodeposition provides a feasible approach to (1) eliminating the need for a fugitive binder system, (2) reducing thermal postprocessing operations for three-dimensional printing of working parts, and (3) achieving a room temperature fabrication process minimizing the need for thermal postprocessing thereby eliminating residual thermal stresses and dimensional inaccuracies from thermal expansion/contraction associated with processing at elevated temperatures. We also demonstrate the feasibility of direct, single-step fabrication of fully dense parts.",2004
"Robustness and Performance Optimization of Engine Bearing System Using Computer Model and Surrogate Noise","Designing an internal combustion engine involves compromising among multiple performance metrics and targets with multiple control and noise factors. The main challenges are in determining the critical performance metrics, finding the optimal compromise between these metrics, and correctly represent the most important control and noise factors through CAE modeling and optimization. This paper presents a methodology for practical application of robustness and performance optimization using a CAE model. The key element of the methodology is a concept of surrogate noise. With this concept, the multiple noise factors affecting the system performance are represented through a limited number of noise factors for CAE modeling. The other part of the methodology is to substitute complicated and computationally time intensive CAE modeling with a cheap-to-compute Gaussian Kriging model through Optimal Sampling and Design of Experiment. The final part of the methodology is performing multi-criteria robustness and performance optimization as well as performance and robustness confirmation of the optimal design point. The proposed methodology has been applied to a practical problem of designing the IC engine main bearing system. The results of the analysis have provided practical recommendations and directions to drive the main bearing system design. In this paper, the methodology is demonstrated through the presentation of a simplified form of this investigation.",2004
"Design Optimization of Enclosed Liquid Containers With Baffles for Sloshing and Impact","A multidisciplinary optimization method is presented to support the design process of partially-filled liquid containers subject to the disciplines of sloshing and impact analysis. This paper represents a part of a study on Multidisciplinary Design and Optimization of liquid containers, and shows experimental techniques used to try to better understand sloshing as a phenomenon and to evaluate the capabilities of the commercial Computational Fluid Dynamics (CFD) code in question. Experimental validation includes qualitative comparison of visual free-surface behavior and quantitative comparisons of pressure measurements in the time and frequency domain. The liquid motion exhibits good comparisons in time with some deviations in wave amplitude due to a modification of the low frequency content of the input signal to the CFD simulation. This modification was caused by both the experimental signal filtration process and deficiencies in the low-frequency measurement capability of the accelerometer. In the frequency domain the first two odd oscillatory modes are accurately captured. A candidate objective function for the quantitative evaluation of the sloshing phenomenon is proposed. Using the response surface method in LS-OPT, various single (sloshing or impact only) and multidisciplinary optimization formulations are presented and results are examined. As expected, the multidisciplinary optimum proved to be a compromise between the optima obtained when considering the two single disciplines independently.",2004
"Design for Project Change Management: Part 1 — Configuration Design","A new systematic approach to identify the optimal design configuration and attributes to minimize potential construction project changes is introduced in this research. The first part of this paper focuses on the configuration design aspect. In this research, the relations between design configurations and construction tasks are modeled by axiomatic design matrices. The design configuration that is most independent to the construction tasks is identified based upon the axiomatic design approach. In addition, estimation of potential project change cost due to the potential design configuration changes is also discussed. Case studies in pipeline engineering design and construction have been conducted to show the effectiveness of the introduced approach.",2004
"Design for Project Change Management: Part 2 — Attribute Design","This research introduces a new systematic approach to identify the optimal design configuration and attributes to minimize the potential construction project changes. The second part of this paper focuses on the attribute design aspect. In this research, the potential changes of design attribute values are modeled by probability distribution functions. Attribute values of the design whose construction tasks are least sensitive to the changes of these attribute values are identified based upon Taguchi Method. In addition, estimation of the potential project change cost due to the potential design attribute value changes is also discussed. Case studies in pipeline engineering design and construction have been conducted to show the effectiveness of the introduced approach.",2004
"Moment Matching for Sensitivity Analysis of Probabilistic Model Output","With the advent of highly complex engineering simulation models that describe the relationship between input variables and output response, the need for an efficient and effective sensitivity analysis is more demanding. In this article, a generalized approach that can provide efficient as well as accurate global sensitivity indices is developed. The approach consists of two steps: running an orthogonal array based experiment using moment-matched levels of the input variables and followed by a variance contribution analysis. The benefits of the approach are demonstrated through three different examples.",2004
"Product Design Selection With Variability in Preferences for an Implicit Value Function","Many existing selection methods require that the Decision Maker (DM) state his/her preferences precisely. However, the DM may not have enough information about the needs of end users thus causing variability in the preferences. To address this problem, we present a method for selection that accounts for variability in the DM’s preferences. Our method is interactive and iterative and assumes only that the preferences of the DM reflect an implicit value function that is quasi-concave and non-decreasing with respect to attributes. Due to the variability, the DM states his/her preferences with a range for Marginal Rate of Substitution (MRS) between attributes at a series of trial designs. The method uses the range of MRS preferences to eliminate “dominated designs” and find a set of “non-eliminated designs”. We present a heuristic to reduce the set of non-eliminated designs and obtain a set of “potentially optimal designs”. The significance of potentially optimal designs is that only one of these designs will be the most preferred for any subset of the range of MRS preferences. We present a payload design selection example to demonstrate and verify that our method indeed finds the set of potentially optimal designs.",2004
"A Formal Approach to Handling Conflicts in Multiattribute Group Decision Making","The Hypothetical Equivalents and Inequivalents Method (HEIM) has been developed to support decision making in multiattribute problems where one decision maker is making the decision. In this paper HEIM is modified to support group decision making in multiattribute problems, resulting in the Group Hypothetical Equivalents and Inequivalents Method (G-HEIM). Instead of aggregating attribute weights or overall alternative values from each individual as is common in other group decision methods, G-HEIM operates by aggregating individual preferences. It is recognized that in group decision making, common preferences among group members can rarely be guaranteed, unless individual freedom is greatly limited. G-HEIM instead allows individuals to freely express preferences over a number of hypothetical alternatives and then explores the level of conflict or differences from the aggregated group preferences. The relationship between the level of conflicting preferences and the usability of the resulting decision is also directly studied using the G-HEIM. An automotive selection example is used to illustrate the approach.",2004
"Convergence and Stability in Distributed Design of Large Systems","Decentralized systems constitute a special class of design under distributed environments. They are characterized as large and complex systems divided into several smaller entities that have autonomy in local optimization and decision-making. The mechanisms behind this network of decentralized design decisions create difficult management and coordination issues. Standard techniques to modeling and solving decentralized design problems typically fail to understand the underlying dynamics of the decentralized processes and therefore result in suboptimal solutions. This paper aims to model and understand the mechanisms and dynamics behind a decentralized set of decisions within a complex design process. This paper builds on already existing results of convergence in decentralized design for simple problems to extend them to any kind of quadratic decentralized system. This involves two major steps: developing the convergence conditions for the distributed optimization problem, and finding the equilibrium points of the design space. Illustrations of the results are given in the form of hypothetical decentralized examples.",2004
"Transient Root Cause Analysis: A Model-Based Systems Engineering Methodology","This paper presents a model-based systems engineering methodology that can be applied to perform a root cause analysis on ",2004
"Design Optimization of Hierarchically Decomposed Multilevel Systems Under Uncertainty","This paper presents a methodology for design optimization of decomposed systems in the presence of uncertainties. We extend the analytical target cascading (ATC) formulation to probabilistic design by treating stochastic quantities as random variables and parameters and posing reliability-based design constraints. We model the propagation of uncertainty throughout the multilevel hierarchy of elements that comprise the decomposed system by using the advanced mean value (AMV) method to generate the required probability distributions of nonlinear responses. We utilize appropriate metamodeling techniques for simulation-based design problems. A simple yet illustrative hierarchical bi-level engine design problem is used to demonstrate the proposed methodology.",2004
"Purely Declarative Feature-Based Design With Feature Type Property Maintenance","Commercial feature-based design systems are based on describing the design model in some form of sequential representation of primitive shapes and operations called features. In these systems, the overall design process, the behavior of building blocks and the characteristics of the final model, are governed by the construction sequence. These systems do not check for the conformity of the final shape with the actual design intent of features, and allow their design and engineering intent to be altered during the design process. The research work presented here describes a new design methodology and feature representation for facilitating a design environment that is independent of any construction order or constraint-based dependencies and provides a mechanism for maintaining design and engineering intent of the design features. The methodology works by dynamically evaluating the features using a planning algorithm such that the validity of each feature is maintained. These are intended to serve as a generic template that can be used to design and develop specific design features and CAD software systems.",2004
"A Weighted Three-Point-Based Strategy for Variance Estimation","In manufacturing processes, it is widely accepted that uncertainty plays an important role and should be taken into account during analysis and design processes. However, uncertainty quantification of its effects on an end-product is a very challenging task, especially when an expensive computational effort is already needed in deterministic models such as sheet metal forming simulations. In this paper, we focus our work on the variance estimation of the system response. A weighted three-point-based strategy is proposed to efficiently and effectively estimate the variance of the system response. Three first-order derivatives for each variable are used to estimate the nonlinear behavior and variance of the system. The details of the derivation of the approach are presented in the paper. The optimal locations of the three points along each axis in the standard normal space and weights for input variables following normal distributions are proposed as (−1.8257,0.0,+1.8257) and (0.075,0.850,0.075), respectively. For input variables following uniform distributions ",2004
"Hierarchical Arrangement of Characteristics in Product Design Optimization Problems for Deeper Insight Into Optimized Results","This paper proposes a design optimization method for machine products that is based on the decomposition of performance characteristics, or alternatively, extraction of simpler characteristics, to accommodate the specific features or difficulties of a particular design problem. The optimization problem is expressed using hierarchical constructions of the decomposed and extracted characteristics and the optimizations are sequentially repeated, starting with groups of characteristics having conflicting characteristics at the lowest hierarchical level and proceeding to higher levels. The proposed method not only effectively enables achieving optimum design solutions, but also facilitates deeper insight into the design optimization results, and aids obtaining ideas for breakthroughs in the optimum solutions. An applied example is given to demonstrate the effectiveness of the proposed method.",2004
"A Method for Determining the Optimal Direction of the Principal Moment of Inertia in Frame Element Cross-Sections","This paper discusses a method to determine the optimal direction of the principal moment of inertia in frames element cross-sections for the design of mechanical structures at the conceptual design phase. The direction in each frame element is determined by maximizing the structural stiffness. Construction of the optimization procedure is based on the KKT-conditions and the balance of bending moments applied to each frame element. This method is implemented as an application in a structural topology optimization procedure that uses frame elements. Finally, several examples are presented to confirm that the proposed method is useful for the topology optimization method discussed here.",2004
"A Collaborative Rapid Analysis Method for Decision-Making in Assembly Line Design","Many highly accurate computer simulation tools have been developed for assembly line design, such as for simulation of assembly processes, but these tools require much input information and are generally utilized only in detailed design stages. This paper proposes a rapid analysis method for manual assembly line design, which can be utilized in the conceptual design stage. This method is based on a layout tool where design engineers can construct assembly line models using 2- and 3-D views. This method provides design evaluation techniques for multiple important criteria such as volume flexibility, visibility, and so on, using the layout data. Spatial evaluation and quantitative efficiency analyses can be simultaneously performed, which enhance collaborative decision-making in the conceptual design stage.",2004
"Text and Illustration Based Scenario Expressions for Conveying Failure Knowledge","Our “Study of Failure” has shown the effects of failure case illustration and text based diagonal scenario expression to successfully convey the essence of failure cases to the reader. A well drawn failure case illustration generates a good image of the failure event in the readers mind, thus succeeds in passing the failure knowledge to the reader. A carefully produced diagonal scenario expression has the same effect. We demonstrated the power of these two fundamentally different representations through an experiment: A failure case illustration alone was shown to a group of people who were asked to define a diagonal scenario expression for the case. The reverse test started from a diagonal scenario expression to reach an illustration that the group had no prior knowledge about. Our tests showed that people can produce a fairly good representation in the other form starting from either an illustration or a diagonal scenario alone.",2004
"Variant Design Automation: Strategy and Procedure for Storing Design Process Information","When creating a design automation system for a mature product there already exists a complete and functional product design and the task is to retrace the initial design process to find the input parameters, algorithms, rules, relations and solution strategies (design process information) that govern this initial design. This paper presents strategies and procedures for retracing, naming, classifying and storing the design process information governing the design variables of a mature product design, seen from a CAD representation perspective. Emphasis is on strategy for storing the design process information for use with the CAD representation as well as system transparency and efficient reuse of the documented and stored information.",2004
"A Process-Oriented Approach for Management of Product Configuration Models","Efficient product configuration systems have been widely recognized by industrial companies as an important tool for meeting increasing customer requirements for specifically adapted products according to their needs/requirements. The main obstacle in this area has been the long-term maintenance of the product configuration models with the new product definition information generated throughout the product lifecycle. Much of the work in this area has focused on product architecture issues, data modelling techniques and software tools. However, in order to be useful, the models and software applications must be put into the right business process context that is supported by the proper organizational framework. Thus, the paper presents a generic process-oriented approach for change management of product configuration-related information in industrial companies. The process contains steps for identification of new and/or changed product configuration knowledge, request of a change in the product configuration model, evaluation of the request, and finally an update of the product configuration model in the system. In addition, there is a description of employees’ competence profile descriptions and the organizational roles needed to support an effective product configuration management process in an industrial company.",2004
"Design of a Bimorph Driven Meander-Line Structure for Parts Feeder Application","A novel meander-line structure implemented with bimorph piezoelectric actuators driven by alternating current power is developed in this article. Via the generated traveling wave, this mechanism is able to transport parts. Dynamic model of the structure as well as motion trajectory and optimal transport feed rate is studied, and also verified by the practical experiment.",2004
"Optimisation and Robust Design in Aero Engine Development","Recent developments in computer capabilities and software enabled the application of deterministic optimization and Robust Design methods in real world aero engine development programs. This paper describes the methods used and shows several applications of this technology. The first example is the application of a Monte-Carlo simulation to support design decisions in the HP turbine casing air system. Here the main goal was to achieve a robust design addressing the variation of build tolerances on flow areas. The variation of parameters as mass flows, pressures and temperatures based on 5000 permutations of the base model give a high confidence level for achieving reliable system behavior for a large population of engines. In addition, dependencies of result parameters on input variations indicate the main levers for system improvement. A second example is the optimization of compressor discs. Here the main emphasis was on the influence of manufacturing tolerances and on the best method to evaluate these tolerances for longer running analysis tasks. Therefore, results of a full Monte-Carlo simulation are compared with results based on two surrogate models, a response surface and a Taylor series expansion. As a final example the optimization of a HP turbine disc for which a Design of Experiment has been performed to generate a response surface model is discussed. Using the response surface data the life variability due to assumptions in the thermal modeling have been quantified and used to adjust the constraints for the subsequent deterministic optimization for weight of the HP turbine. Using deterministic optimization and especially Robust Design methods a considerable decrease in development time and cost as well as an increased product quality and reliability have been achieved. However, deterministic optimization methods alone normally drive designs on to the constraint boundaries, leading to “cliff-edge” designs. Therefore, the application of Robust Design methods is required to increase the product reliability. These methods still require a considerable computing effort, so the widespread application is just starting.",2004
"Decoupled and Single Loop Methods for Reliability-Based Optimization and Robust Design","Several procedures have been developed in the literature for reliability-based design optimization (RBDO), including the Reliability Index Approach (RIA), the Performance Measure Approach (PMA), and more recent techniques wherein the reliability and optimization calculations are decoupled. This paper extends the decoupled approach to include standard deviations as design parameters and wherein simulation or other methods can replace the traditional first order analytical method for reliability assessment. The methods are extended to robust design and their applicability is investigated. The paper also investigates a single loop method and extends it for the robust design problem. The accuracy and computational efficiency of the various RBDO methods are compared.",2004
"An Integrated Robust Design and Marketing Approach for Product Design Selection Process","We present an integrated engineering design and marketing approach to facilitate the selection of a robust set of product designs to carry forward to the prototype stage. Our approach considers variability (i.e., noise or uncertainty) in both (i) engineering design domain, and (ii) customer preferences in marketing domain, to prune a set of design alternatives to a manageable size. In the design domain, our approach evaluates performance and feasibility robustness of a design alternative when there are variations in uncontrollable parameters. The goal of our approach in the design domain is to obtain a set of design alternatives that shows the best possible performance while maintaining feasibility even if the alternatives are subject to applications and environments that are different from their standard laboratory conditions (i.e., nominal parameter values). In the marketing domain, our approach considers the impact of performance variations in different usage situations and conditions on customer preferences and the uncertainties and sampling errors in estimating customer preferences. In addition, competitive products and their positions are considered in pruning the set of design alternatives. We illustrate our approach in the context of the design of a cordless power tool example, which highlights the advantages of using our approach.",2004
"A CAD Package for High-Speed Cam Design Based on Direct Multiple Shooting Optimal Control Techniques","High-speed automotive valve train design requires realistic models of the valve train. However, this frequently results in highly nonlinear systems with discontinuities and constraints. Optimality criteria and trade-offs for the designs are frequently performed through a process of simulation and iterative refinement. This paper presents CamOE, a cam design optimization package based on direct multiple shooting optimal control theory, incorporating structured sequential quadratic programming. The code allows the designer to incorporate the constraints of importance and to consider and synthesize appropriate optimality criteria. This allows him or her to synthesize the cam profile at the design stage without resorting to a tedious trial-and-error design process. This paper presents CamOE as a software environment that permits rapid feedback to the designer through the process of numerical experiments in specifying criteria and constraints on the automotive valve train.",2004
"A Fuzzy Dynamic Programming Approach for Mixed-Discrete Multistage Decision Processes","Many engineering optimization problems can be considered as multistage decision-making problems. If the system involves uncertainty in the form of linguistic parameters and vague data, a fuzzy approach is to be used for its description. The solution of such problems can be accomplished through fuzzy dynamic programming. However, most of the existing fuzzy dynamic programming algorithms can not deal with mixed-discrete design variables in the optimization of mechanical systems containing fuzzy information. They often assumed that a fuzzy goal is imposed only on the final state for simplicity, the values of fuzzy goal and other parameters need to be predefined, and an optimal solution is obtained in the continuous design space only. To better reflect the nature of uncertainties present in real-life optimization problems, a mixed-discrete fuzzy dynamic programming (MDFDP) approach is proposed in this work for solving multistage decision-making problems in mixed-discrete design space with a fuzzy goal and a fuzzy state imposed on each stage. The feasibility and versatility of the proposed method are illustrated by considering the design of a four-bar truss. To the authors’ knowledge, this work represents the first fuzzy dynamic programming method reported in the literature for dealing with mixed-discrete optimization problems.",2004
"Structural Topology Optimization Under Impact Loads Using Beam Ground Structures","This work presents a methodology to find the optimal topology of a three-dimensional structure subject to impact loads, using the approach of ground structure. The method uses of the concept of topology optimization as a material allocation problem, which has been successfully used in the past to design structures modeled with shell and solid finite elements in the automotive industry. A simple example is shown to demonstrate the method.",2004
"Objective Function Based Pattern Search: A Computationally Efficient Algorithm for 3D Component Layout","A new class of pattern search algorithms called Objective Function-based Pattern Search is proposed for 3D Layout. These algorithms are driven by decreasing expected change in objective function rather than by decreasing step size. Current pattern search algorithms rely on decreasing step size of all patterns at the same rate. Also, all translation and rotation patterns are active at all step sizes of patterns. The new class of algorithms decreases the step sizes of the patterns based on the expected change in objective function value due to that pattern. Also, whether a pattern is active or inactive at a particular step size is decided by the expected change in objective function due to that pattern at that step size. The new algorithm is found to be up to 50% faster in runtime compared to previous pattern search based algorithms.",2004
"Toward an Information Management Infrastructure for Product Family Planning and Mass Customization","Complex new product development requires numerous decisions by many individuals and groups, which are often geographically and temporally distributed. There is a need to share and coordinate distributed resources and synchronize decisions, and recent advances in information technology (IT) pose an untapped potential for assisting in the capture, storage, retrieval and facilitated use of product development information. We exploit IT to address this problem through the proposed approach to Product Family Planning. By sharing assets such as components, processes and knowledge across a family of products, companies can efficiently develop differentiated products and increase the flexibility and responsiveness of their product realization process. In this paper we describe our recent efforts in realizing an information management infrastructure for product family planning and platform customization. In particular, we focus on three current research thrusts to identify product platform leveraging strategies to support future product family planning: (1) an evolutionary approach to product platforming, (2) a bottom-up approach to product platforming, and (3) industry-based platform case studies. Future research directions are also outlined.",2004
"Application of Math-Based Marketing and Financial Tools in an Automated Parametric Design Framework","A suite of math-based marketing and financial tools has been deployed and exercised within an automated, multidisciplinary parametric design framework. This suite of tools includes a market share estimator based on Cook’s S-Model, a Technical Cost Model for estimating the variable and fixed costs of the vehicle’s body system, a database of cost estimates for other vehicle systems, and a profit estimator developed from a standard accounting template. Development of the S-Model market share estimator included completion of a Demand-Price analysis for the midsize sedan segment and collection of publicly available value curves predominantly covering the powertrain performance and interior roominess disciplines. A flexible input-output interface was developed for the Technical Cost Model to provide a means of propagating changes in body design parameters throughout the framework. A series of exercises including analysis of a baseline vehicle, optimization of a hypothetical vehicle concept for net income, and a hypothetical architectural parameter study were conducted to demonstrate the capabilities of a multidisciplinary parametric design framework enabled with marketing and financial tools. These exercises demonstrate that existing engineering and business discipline tools can effectively interoperate to design for profitability in a multidisciplinary parametric design environment. They also illustrate several key challenges in automated design for profitability, such as those encountered in defining the role of price as a design variable in a tightly coupled design-for-profit system and in generating cost estimates using a continuously variable design representation.",2004
"An Information Theoretical Perspective on Design Optimization","Design optimization is becoming and increasingly important tool for design. In order to have an impact on the product development process it must permeate all levels of the design in such a way that a holistic view is maintained through all stages of the design. The design process can be viewed as a process of increasing the information of the finished product. Design optimization is on one hand a part of the design process, but can also be used as a metaphor for the whole design process. In this paper an information theoretical approach is taken to establish a performance criterion for an optimization method. Furthermore, this approach is extended do describe the design process.",2004
"Economics of Sacrificial Fixturing for CNC Machining and Rapid Manufacturing","This paper presents a fixturing method for sacrificial fixturing machining using CNC equipment. The focus of the paper is not on the method itself, but on the economics of sacrificial fixturing CNC machining, which defines the domain of use for the results described in the paper. The paper presents an economic model of machining, and then analyzes the use of the method as a function of: the number of parts to be produced, the ratio of material removed to final part volume, the number of features on the part, and the basic part geometry. We conclude that sacrificial fixturing is a very practical method that should be seriously considered when machining small batches of parts, rapid prototyping with CNC machining and parts with some particular geometric characteristics.",2004
"A Benchmark Comparison of CAD 5-Axis Machining Packages","In this paper, parts from Ford GT were machined based on tool path created using Curvature Matched Machining and three other popular CAD systems. Five-axis flat end mill methods are used as the baseline of comparison. The performance of these CAD packages was compared using the benchmark of tool path density, surface finish, and post-machining finishing time. Results show that CM2 has advantage over today’s leading CAM capability in terms of both machining efficiency and tool path computation time.",2004
"A Comparative Study of Optimal Design for an Inkjet Printer Tube With and Without Performance Variations","As a new generation of printing technology, thermal inkjet (TIJ) has been widely adopted to meet the increasing demand for high printing quality and efficiency at an affordable price. High air barrier tubes play an important role in the reliable operation of the printhead in a commercial thermal inkjet printer. Desired tube qualities include low stiffness and low pressure drop, along with others. Tube stiffness and pressure drop can be lowered through the selection of proper tube layer configuration, geometry and material properties. However, the existing tube design practice is highly heuristic and design results are not optimal. Furthermore, there is no robust design consideration in the current design, and it is hard to trace and compare the tube quality from different groups of designers. In this work, a comparative study using industrial examples is conducted to search for a reusable robust design methodology for TIJ tube design. Two cases using different optimization strategies are investigated. In case A, a performance based optimization strategy is used, and the design objectives are the target performances without variation consideration. In Case B, a robust design based optimization strategy is used, and the variations of the target performances are incorporated in the design objectives. A comparison of their results with the current practice shows that the optimization strategies can greatly improve the efficiency of the current tube design process. More important, the optimization strategy with variation consideration yields robust results and provides much richer design knowledge to support designers with various experiences to make better decisions.",2004
"Reliability-Based Design Optimization Methods","Reliability-based design optimization (RBDO) methods are optimization algorithms that utilize reliability methods to evaluate probabilistic constraints and/or objective functions used to prescribe reliability. For practical applications, it is important that RBDO methods are efficient, i.e, they only require a manageable number of numerical evaluations of underlying functions since each one can be computationally expensive. The type of reliability methods and the manner in which they are used in conjunction with optimization algorithms strongly affect computational efficiency. The first order reliability method (FORM) and its inverse are proved to be efficient and widely accepted for reliability analysis. RBDO methods have therefore employed FORM or inverse FORM to numerically evaluate probabilistic constraints and objective functions. During the last decade, the efficiency of RBDO methods has been further improved through problem reformulation. Our goal is to present RBDO methods from a mathematical optimization perspective by formalizing FORM, inverse FORM, and associated RBDO formulations. This new perspective helps not only to clearly reveal their close relationships but also provides a common ground for understanding different types of RBDO methods. Using numerical studies reported in the literature, we indicate the numerical efficiency, convergence, and accuracy of existing RBDO methods.",2004
"A Reliability-Based Design Method Using Simulation Techniques and Efficient Optimization Approach","A novel reliability-based design optimization (RBDO) method using simulation-based techniques for reliability assessments and efficient optimization approach is presented in this paper. In RBDO, model-based reliability analysis needs to be performed to calculate the probability of not satisfying a reliability constraint and the gradient of this probability with respect to each design variable. Among model-based methods, the most widely used in RBDO is the first-order reliability method (FORM). However, FORM could be inaccurate for nonlinear problems and is not applicable for system reliability problems. This paper develops an efficient optimization methodology to perform RBDO using simulation-based techniques. By combining analytical and simulation-based reliability methods, accurate probability of failure and sensitivity information is obtained. The use of simulation also enables both component and system-level reliabilities to be included in RBDO formulation. Instead of using a traditional RBDO formulation in which optimization and reliability computations are nested, a sequential approach is developed to greatly reduce the computational cost. The efficiency of the proposed RBDO approach is enhanced by using a multi-modal adaptive importance sampling technique for simulation-based reliability assessment; and by treating the inactive reliability constraints properly in optimization. A vehicle side impact problem is used to demonstrate the capabilities of the proposed method.",2004
"Assessing Product Architecture Costing: Product Life Cycles, Allocation Rules, and Cost Models","Product families and product platforms have been suggested as design strategies to serve heterogeneous markets via mass customization. Numerous, individual cost advantages of these strategies have been identified for various life cycle processes such as product design, manufacturing, or inventory. However, these advantages do not always occur simultaneously, and sometimes even counteract each other. To develop a better understanding of these phenomena, this paper investigates the cost implications of the underlying design decision: the product architecture choice. The investigation includes factors such as product life cycle phases, allocation rules, and cost models, all of which impact the cost analysis results. Based on this investigation, directions for future research on product architecture costing are provided.",2004
"Unified Distance Queries in a Heterogeneous Model Environment","Computing the minimum distance between two models in a virtual scene is a fundamental operation useful in simulation, path planning, haptics, and modeling. In an environment with heterogeneous model representations, distance functions can be difficult to formulate and may require multiple specialized methods. In this paper, we demonstrate a generalized method for finding the distance between models with different representations and demonstrate it on a variety of models.",2004
"The Role of Constraints and Human Interaction in Evolving MEMS Designs: Microresonator Case Study","In this paper we review the current state of automated MEMS synthesis with a focus on generative methods. We use the design of a MEMS resonator as a case study and explore the role that geometric constraints and human interaction play in a computer-aided MEMS design system based on genetic algorithms.",2004
"Two-Level Approximation Method for Reliability-Based Design Optimization","In order to model uncertainties and achieve the required reliability, Reliability Based Design Optimization (RBDO) has evolved as a dominant design tool. Many methods have been introduced in solving the RBDO problem. However, the computational expense associated with the probabilistic constraint evaluation still limits the applicability of the RBDO to practical engineering problems. In this paper, a Two-Level Approximation method (TLA) is proposed. At the first level, a reduced second order approximation is used for better optimization solution; at the second level a linear approximation is used for faster reliability assessment. The optimal solution is obtained interatively. The proposed method is tested on certain numerical examples, and results obtained are compared to evaluate the cost-effectiveness.",2004
"Product Platform Design Through Sensitivity Analysis and Cluster Analysis","Product platform design plays a vital role in determining two important aspects of a products family: efficiency (cost savings due to commonality) and effectiveness (capability to satisfy performance requirements). In this work, sensitivity analysis and cluster analysis are used to improve both efficiency and effectiveness of a product family design. A strategy of commonization is employed to form a platform. An illustrative example is used to demonstrate the merits of the proposed method, and the results are compared with existing results from the literature.",2004
"A Full Parametric Model for Turbomachinery Blade Design and Optimisation","This paper presents a full parametric model of a turbomachinery blade. The model forms the geometric backbone of a new aerodynamic design suite, which aims at speeding up the coupled 2D/3D aerodynamic design process. The approach employed here follows the basic design concepts of turbomachinery blades, which are typically defined by a series of cross-sectional aerofoils stacked at their radial location to a three-dimensional blade. Unlike the geometry management in current design systems, the paradigm of a CAD based Master Model has been incorporated in the geometry definition and the corresponding software architecture. Therefore all blade features have been modelled as computational components in the flexible object-oriented software environment. The blade parameterisation enables the 2D aerofoil construction either from the common superposition of the camber line and thickness distribution or the direct control of the suction and pressure side. The sensitivity of the aerofoil aerodynamic performance with respect to a design parameter can be quickly assessed with a fast 2D flow solver. The parameters of the radial stacking line define the axial and tangential shift of each section. The parametric concept facilitates the inclusion of specific shape control techniques such as curvature manipulation and surface smoothing. Furthermore the use of optimisation methods is greatly simplified by the modular program structure, which allows to access single modules of the blade design tool in a batch job. Since the blade design process involves different coordinate systems, unique mapping functions are essential for a consistent update of the blade geometry during a design cycle. The interface to the CAD system is based on the standard data exchange format STEP. The CFD interface makes use of the NetCDF data format for automatic grid generation.",2004
"The Performance Moment Integration Method for Reliability-Based Robust Design Optimization","Reliability-based robust design optimization deals with two objectives of structural design methodologies subject to various uncertainties: reliability-based design and robust design. A reliability-based design optimization deals with the probability of failure, while a robust design optimization minimizes the product quality loss. In general, the product quality loss is described by using the first two statistical moments: mean and standard deviation. In this paper, a performance moment integration (PMI) method is proposed by using numerical integration scheme for output response to estimate the product quality loss. For the reliability part of the reliability-based robust design optimization, the performance measure approach (PMA) and its numerical method, hybrid-mean value (HMV) method, are used. New formulations of reliability-based robust design optimization are presented for three different types of robust objectives, such as smaller-the-better, larger-the-better, and nominal-the-better types. Examples are used to demonstrate the effectiveness of reliability-based robust design optimization using the proposed PMI method for different types of robust objective.",2004
"Segmentation of Noisy Laser-Scanner Generated Meshes With Piecewise Polynomial Approximations","Laser scanners offer a fast and simple way of collecting large amounts of geometric data from real-world objects. Although this aspect makes them attractive for design and reverse engineering, the laser-scanner data is often noisy and not partitioned into meaningful surfaces. A good partitioning, or segmentation, of the scanner data has uses including feature detection, surface boundary generation, surface fitting, and surface reconstruction. This paper presents a method for segmenting noisy three-dimensional surface meshes created from laser-scanned data into distinct regions closely approximated by explicit surfaces. The algorithm first estimates mesh curvatures and noise levels and then uses the curvature data to construct seed regions around each vertex. If a seed region meets certain criteria, it is assigned a region number and is grown into a set of connected vertices approximated by a bicubic polynomial surface. All the vertices in a region are within known distance and surface normal tolerances from their underlying surface approximations. The algorithm works on noisy or smooth data and requires little or no user interaction. We demonstrate the effectiveness of the segmentation on real-world examples.",2004
"Solid Modeler Evaluation and Comparison Cycle: A Methodology for Optimum Selection of Modeling Software","This study proposes a methodology that would enable a design educator or a design practitioner to optimally select a solid modeling software (solid modeler) for varying objectives. Tasks accomplished to propose the methodology include: (1) reviewing past literature to compile the criteria used for selecting solid modelers, (2) preliminary comparison of a number of solid modelers on established criteria, (3) running designed experiments for comparing the user performance on predetermined solid modeling functions, and (4) compiling the experience gained as a generic methodology. The application was completed over a two-year period while a systematic selection process was undertaken at The Pennsylvania State University (Penn State). This paper documents the entire selection process including the design performance data collected. In addition the performance data, the results of the preliminary preference data are also reported. The set of outcomes of the study is expected to aid companies and design educators in making solid modeler selection decisions.",2004
"Vehicle Structure Optimization for Crash Pulse","In vehicle safety engineering, it is important to determine the severity of occupant injury during a crash. Computer simulations are widely used to study how occupants move in a crash, what they collide during the crash and thus how they are injured. The vehicle motion is typically defined for the occupant simulation by specifying a crash pulse. Many computer models used to analyze occupant kinematics do not calculate both vehicle motion and occupant motion at the same time. This paper presents a framework of response surface methodology for the crash pulse prediction and vehicle structure design optimization. The process is composed of running simulation at DOE sampling data points, generating surrogate models (response surface models), performing sensitivity analysis and structure design optimization for time history data (e.g., crash pulse). Within this framework, the engineer can perform DOE sampling, surrogate modeling, main effect plot within any time interval, and design optimization. Some recent applications are presented to demonstrate how these approaches are employed for a vehicle structure design.",2004
"Analytical Variance-Based Global Sensitivity Analysis in Simulation-Based Design Under Uncertainty","The importance of sensitivity analysis in engineering design cannot be over-emphasized. In design under uncertainty, sensitivity analysis is performed with respect to the probabilistic characteristics. Global sensitivity analysis (GSA), in particular, is used to study the impact of variations in input variables on the variation of a model output. One of the most challenging issues for GSA is the intensive computational demand for assessing the impact of probabilistic variations. Existing variance-based GSA methods are developed for general functional relationships but require a large number of samples. In this work, we develop an efficient and accurate approach to GSA that employs analytic formulations derived from metamodels of engineering simulation models. We examine the types of GSA needed for design under uncertainty and derive generalized analytical formulations of GSA based on a variety of metamodels commonly used in engineering applications. The benefits of our proposed techniques are demonstrated and verified through both illustrative mathematical examples and the robust design for improving vehicle handling performance.",2004
"Building Surrogate Models Based on Detailed and Approximate Simulations","Preliminary design of a complex system often involves exploring a large design space. This may require repeated use of computationally expensive simulations. To ease the computational burden, surrogate models are built to provide rapid approximations of more expensive models. However, the surrogate models themselves are often expensive to build because they are based on repeated experiments with computationally expensive simulations. An alternative approach is to replace the detailed simulations with simplified approximate simulations, thereby sacrificing accuracy for reduced computational time. Naturally, surrogate models built from these approximate simulations will also be imprecise. A strategy is needed for improving the precision of surrogate models based on approximate simulations without significantly increasing computational time. In this paper, a new approach is taken to integrate data from approximate and detailed simulations to build a surrogate model to describe the relationship between output and input parameters. Experimental results from approximate simulations form the bulk of the data, and they are used to build a model based on a Gaussian process. The fitted model is then ‘adjusted’ by incorporating small amounts of data from detailed simulations to obtain a more accurate prediction model. The effectiveness of this approach is demonstrated with a design application for a cellular material that is used to cool a microprocessor. The emphasis is on the method and not on the results ",2004
"Graphical Modeling Environment and Supporting Framework for Function-Based Conceptual Design","As engineering products become more complicated, collaboration among multi-disciplinary design teams that are separated by location, time and across organizations is becoming an increasingly difficult task. To be effective, collaboration requires exchanging, interpreting and integrating knowledge in various locations. According to a recent study, the cost of this breakdown in knowledge in the automotive industry alone is at least $1 billion per year. There has been a significant amount of research in recent years to improve the accessibility of knowledge during design. Very little has, however, been invested in format, flow and relationships of knowledge to support the ",2004
"Relative Entropy Based Method for Global and Regional Sensitivity Analysis in Probabilistic Design","To overcome the limitations of existing variance-based methods for Probabilistic Sensitivity Analysis (PSA) in design under uncertainty, a new PSA approach based on the concept of relative entropy is proposed. The relative entropy based method evaluates the impact of a random variable by measuring the divergence between two probability density functions of a response. The method can be applied both globally over the whole distribution of a performance response (called global response probabilistic sensitivity analysis–GRPSA) and in any regional range of a response distribution (called regional response probabilistic sensitivity analysis–RRPSA). The former is the most useful for studying variable impact on robust design objective, while the latter provides insight into reliability constraints. The proposed method is applicable to both the prior-design and post-design stages, for variable screening and uncertainty reduction, respectively. The proposed method is verified by numerical examples and industrial design cases.",2004
"A Haptic System for Virtual Prototyping of Polygonal Models","Virtual prototyping attempts to replace physical models with virtual models for the purpose of design evaluation. One task a virtual prototyping environment can address is the accessibility of the components of a mechanical system. In this paper, we demonstrate a haptics-based virtual prototyping system for finding collision-free paths for moving models in complex polygonal environments. The system can handle models and environments with hundreds of thousands of triangles, and augments innate human talents at searching for collision-free paths.",2004
"Influence of Group Cohesion and Information Sharing on Effectiveness of Design Review","Research into group decision-making suggests that, dependent on the information distributed prior to a group discussion, the decision and discussion content can be predicted. While the impact to group decision-making has been studied, its impact on collaborative activities such as design review has not been well investigated. A full factorial design of experiments (3×3, DOE) is conducted to investigate the influence of group cohesion and the awareness of the presence of unshared information among group members on design review effectiveness. The results suggest that awareness may have an effect on locating design issues by representation, functional group domain, and the total amount of design issues located.",2004
"Development of a J2EE Web Application for STEP-Based Design Conformance Checking","Product design needs great team efforts from multi-disciplinary participants, even external partners, for collaborative problem solving. Design conflicts within and between functional teams do occur in such a collaborative design process. Detection and resolution of design conflicts through design conformance checking therefore becomes a critical activity in the joint design problem solving. This paper presents the development of a J2EE application prototype to support the STEP-based design conformance checking. A STEP-compliant information model has been specified to represent 3D CAD objects and other design information, while a knowledge representation model been proposed to describe design rules and constraints. The STEP objects and rule objects are managed and processed by the enterprise Java beans of a J2EE application server, which continuously applies the rule objects to the STEP objects and finally draws a conclusion for the design conformance checking. Application scenarios are discussed in the paper to illustrate the effectiveness of both the STEP/rule objects modeling approaches and the prototype system for support of the design compliance checking in distributed environment.",2004
"A Sequential Exploratory Experimental Design Method: Development of Appropriate Empirical Models in Design","Much of today’s engineering analysis work consists of running complex computer codes (simulation programs), in which a vector of responses are obtained when values of design variables are supplied. To save time and effort in simulation, sampling (design of experiments) techniques are applied to help develop metamodels (empirical models or surrogate models) that can be used to replace the expensive simulations in future design stages. The usage of metamodels also helps designers to integrate inter-disciplinary codes and grasp the relationship between inputs and outputs. In this paper, we focus on a very important topic in studies of sampling and metamodeling techniques, i.e., the sequential design of experiments and metamodeling; the research question is: How to design sequential computer experiments to get accurate metamodels? After discussion of design and metamodeling strategies, a Sequential Exploratory Experimental Design (SEED) method is developed to help identify data points at different stages in metamodeling. Given limited resources, it is expected that more accurate metamodels can be developed with SEED. A single-variable example is used to help illustrate the SEED method.",2004
"Applicability of Design Spaces to Utilize Current Assembly Plant Resources to Produce New Product Family Members","Utilizing available assembly resources can greatly reduce the development time and cost for platforms and new product family members. This paper presents a method to utilize existing assembly plant resources, during the development of new product family members, by comparing existing assembly plant with feasible assembly processes. An assembly sequence design space that can be used to perform new family member process and existing plant utilization trade-off study is presented in the paper. The assembly sequence design space is combinatorial in nature. This research seeks to provide a systematic method to represent and reason with combinatorial design spaces in which these assembly process combinations lie. Models that capture effects of constraints on these spaces, explicitly represent feasible regions, and efficiently enumerate designs within this space are investigated. Application of the assembly sequence space to perform assembly plant utilization trade-off study is demonstrated using a coffeemaker family.",2004
"A Sketch-Based Interface for the Design and Analysis of Simple Vibratory Mechanical Systems","We describe a sketch-based interface designed to provide engineers with a computer environment similar to pen and paper. With our interface, users can construct functional engineering models simply by drawing sketches on a computer screen. Unlike paper sketches, however, our interface allows users to interact with their sketches in real time to modify existing objects and add new ones. To demonstrate the utility of our system, we have developed a sketch-based interface for designing and analyzing simple vibratory mechanical systems. The technical contributions of our work include: (1) a sketch parsing method for automatically locating the distinct graphical symbols in a sketch, (2) a general-purpose, trainable symbol recognizer, and (3) special purpose prerecognizers that consider shape information and make use of drawing conventions.",2004
"Trim Loop Closure for Enhanced CAD Interoperability","The transfer of design data among different CAD systems or subsequent downstream analysis applications is critically important to the acceleration of the product development cycle. Since each vendor has its own proprietary native file format, this transfer of data among differing systems is difficult at best. International standards such as IGES and STEP have evolved to address this challenge, but they are generally not sufficiently explicit. Each vendor writes its own “flavor” of the standard that other applications may not understand. This paper bridges a gap between disparate systems by developing a strategy to assess the completeness and robustness of models represented in IGES or STEP format, and a technique to either repair the representation or add missing information so that a downstream application can properly interpret it. The method ensures that the receiving system gets a full and accurate NURBS-based representation: the original surface, the corresponding full complement of model space trim curves, and the corresponding full complement of parameter space trim curves. With all the information present, the downstream system is more likely to receive the information it requires to interpret the model.",2004
"Haptically Guided Filtering for Reverse Engineering","Reverse engineering of mechanical systems often begins with large datasets produced from laser scanning of physical artifacts. Commonly it is necessary to remove noise and filter them; however, selecting noisy regions and preserving sharp edges on desired features is difficult using standard GUI interfaces. We demonstrate a haptic interface for marking and preserving features in noisy data and for performing local smoothing operations. The force-feedback provides a natural interface for these operations.",2004
"Design Configuration of Vehicle With Domain Knowledge Enhancement","Configuration design and packaging optimization correspond to finding the optimal placement of a series of objects in a system while satisfying functional requirements and minimizing criteria. The research presented in this paper is applied to the configuration design of vehicles and more specifically the US Army FMTV (Family of Medium Tactical Vehicles). This paper presents the latest developments of the design methodology based on a multiple objective genetic algorithm. A swap operator specifically constructed for packaging problems is presented. For this multi-criteria problem, the goal of the methodology is to explore the objective space in order to find multiple Pareto designs. This research is motivated by the need to add non-conventional components, namely, a fuel cells auxiliary power unit and its associated modules, on the FMTV. Three objectives are considered: vehicle dynamic behavior, maintainability, and survivability. The methodology uses several in-house and commercial analysis packages to evaluate the fitness of the evolving designs. The new approach is systematically evaluated comparing the results to those of the original method with respect to its ability in generating the Pareto front of the multi-criteria design problem.",2004
"An Exploration-Estimation Algorithm for Synthesis and Analysis of Engineering Systems Using Minimal Physical Testing","We describe a new general algorithm for the automated design, analysis and repair of nonlinear physical systems. The process iterates a two-phase exploration-estimation cycle. The exploratory phase seeks a new improvement or test to perform to the system based on some initial internal model. The estimation phase performs the suggested operation and observes the outcomes; it then improves the internal model so as to explain all observations so far. This process relies on very few, targeted, and carefully planned interactions with the physical systems. We describe an implementation of this method using two evolutionary algorithms, where the exploratory phase uses a simulator to evolve improvements or tests, and the estimation phase uses observations to evolve the simulator itself. We demonstrate this algorithm for analysis, design and repair of electromechanical systems.",2004
"Quantifying Profit and Loss Associated With Failure Cases","Failures have impact on the society as well as on the entity that caused the failure. The size of impact varies with each case. Although large scale accidents will cause great impact on the society and the originator, it is not only the size of failure that determines the size of impact on the originator. When an unethical corporate misconduct is revealed, the company at times will disappear by loss of business or administrative disposition. To measure the impact of failures on the originator and to help make decisions of whether to disclose or cover the event, we defined two quantities associated with failure; “Profit of Failure” and “Loss of Failure”. The former measures monetary gain for covering up a failure, and the later the loss in case the failure is disclosed. We applied our method of calculation to 18 cases of past failures and identified different groups. Some cases, the loss exceeds the profit and business owners are encouraged to publicly disclose the event as soon as it internally becomes known to keep the damage smaller. In other cases, the loss is smaller than the profit and in which case, business owners may decide to cover up the event. Even in the later case, business owners may want to disclose the event anyway because recently changed regulations protect the whistle blowers better and for ethical reasons.",2004
"Using the Compromise Decision Support Problem in Microsystem Design: A Formulation for a Miniature Parylene Gas Chromatographic Column","The concurrent consideration of design and manufacturing requirements at the early stages of design is one of the cited challenges in microsystem design. In this paper, we take the first steps, through an example, towards addressing these issues through the use of the compromise Decision Support Problem (cDSP). The cDSP is a domain-independent hybrid multiobjective decision support formulation utilized in engineering design. The design of a parylene microchannel for a microscale gas chromatography system is refined using the cDSP. The objective is to adjust the geometry of the microchannel to create a satisficing design for one fabrication goal and two performance goals. The cDSP is utilized for five scenarios, one in which all three goals are given equal priority, one for each of three goals when they are given first priority, and one in which the performance goals are given equal priority. We are more interested in demonstrating the method than the results per se. Our goal is to show how microsystem designers can use the cDSP to gain some insight into how these goals interact and how design decisions can be made with this insight.",2004
"Improved Disassembly Matrices for Disassembly Processes","The combined interference matrix and the combined contact matrix of product components with connection matrices, special connection relations, the disassembly sequence matrix, instability of sub-assemblies, changes of sub-assembly disassembly direction or tools, platform and the effect of gravity are investigated to obtain the optimum disassembly process. This methodology improves Huang and Huang’s method. Software is generated and two products were used as examples. Results of optimum disassembly processes were same as those obtained from other researchers. Therefore, the methodology is feasible for study of disassembly processes of products, and software can reduce the computer memory and time.",2004
